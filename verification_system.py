"""
ìë™ ê²€ì¦ ì‹œìŠ¤í…œ - ì›ë³¸ PDFì™€ ê²°ê³¼ë¬¼ ë¹„êµ
í…ìŠ¤íŠ¸ ì˜¤ë¥˜/ì˜¤íƒ€ ê²€ì¦ ë° ìë™ ìˆ˜ì •
"""

import os
import re
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from difflib import SequenceMatcher
from collections import Counter

logger = logging.getLogger(__name__)


class VerificationSystem:
    """ì›ë³¸ê³¼ ê²°ê³¼ë¬¼ ìë™ ê²€ì¦ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.common_ocr_errors = {
            # ìì£¼ ë°œìƒí•˜ëŠ” OCR ì˜¤ë¥˜ íŒ¨í„´
            "ê³µì•…": "ê³µì•½",
            "ê²…ë ¥": "ê²½ë ¥",
            "ì •ë”©": "ì •ë‹¹",
            "í›„ë³´ì": "í›„ë³´ì",
            "ì„ ê±°": "ì„ ê±°",
            "ë„ì‘": "ë™ì‘",
            "ìƒë„ë™": "ìƒë„ë™",
            "í˜¹ì„ë™": "í‘ì„ë™",
            "ì‚¬ë‹¹ì˜¤ë™": "ì‚¬ë‹¹5ë™",
            "êµ­ë¯¼ì˜í™": "êµ­ë¯¼ì˜í˜",
            "ë”ë¶ˆì–´ë¯¼ì£¼ë”©": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
            "@ë‚˜kyungwon": "@Lrkyungwon",
            "youtube.com/@ë‚˜kyungwon": "youtube.com/@Lrkyungwon",
            # ê³µì•½ ì œëª© ìˆ˜ì •
            "êµìœ¡íŠ¹êµ¬ ë™ì‘": "ë™ì‘ì„ 8í•™êµ° ìˆ˜ì¤€ìœ¼ë¡œ",
            "ì‚¬í†µíŒ”ë‹¬ ë™ì‘": "ë»¥ ëš«ë¦¬ëŠ” ë™ì‘, ë»¥ëš«ë¦¬ëŠ” ì¶œí‡´ê·¼",
            "ìƒì „ë²½í•´ ë™ì‘": "ëœë“œë§ˆí¬ë¥¼ ë§Œë“¤ê³  ìŠ¤ì¹´ì´ë¼ì¸ì„ ë°”ê¾¸ë‹¤",
            "ì‚¼ì „ë²½í•´ ë“±êµ­": "ëœë“œë§ˆí¬ë¥¼ ë§Œë“¤ê³  ìŠ¤ì¹´ì´ë¼ì¸ì„ ë°”ê¾¸ë‹¤",  # OCR ì˜¤ë¥˜ ëŒ€ë¹„
            "15ë¶„ë„ì‹œ ë™ì‘": "ê±¸ì–´ì„œ 15ë¶„ ë‚´ì— ê³µì›, ë¬¸í™”, ì²´ìœ¡ì‹œì„¤ ì´˜ì´˜íˆ",
            "ë“ ë“ ë³µì§€ ë™ì‘": "ë“ ë“ í•œ ì‚¶ ë“ ë“ í•œ ë¯¸ë˜",
            "ì•ˆì „ì•ˆì‹¬ ë™ì‘": "ê±±ì •ì—†ì´ í–‰ë³µí•œ, ë” ì•ˆì „í•œ ë™ì‘",
            "ì»µì–´ì„œ 15ë¶„ ë‚´ì— ê³µì›, ë¬¸í™”, ì²´ìœ¡ì‹œì„¤ ì¶œì¶œíˆ (15ë¶„ë„ì‹œ ë™ì‘)": "ê±¸ì–´ì„œ 15ë¶„ ë‚´ì— ê³µì›, ë¬¸í™”, ì²´ìœ¡ì‹œì„¤ ì´˜ì´˜íˆ",  # OCR ì˜¤ë¥˜ ë²„ì „
            "ì£¼ìš” ê²½ë ¥": "ì£¼ìš” ì‹¤ì ",
        }

        # ì¤‘ìš” í‚¤ì›Œë“œ (ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•¨)
        self.critical_keywords = [
            "í•µì‹¬ê³µì•½",
            "ê²½ë ¥",
            "ì—°ë½ì²˜",
            "ì •ë‹¹",
            "í›„ë³´ì",
            "ì„ ê±°ì‚¬ë¬´ì†Œ"
        ]

    def verify_conversion(
        self,
        original_pdf_path: str,
        generated_html_path: str,
        extracted_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë³€í™˜ ê²°ê³¼ ê²€ì¦

        Returns:
            ê²€ì¦ ê²°ê³¼ ë° ìˆ˜ì • ì œì•ˆ
        """
        logger.info(f"ê²€ì¦ ì‹œì‘: {Path(original_pdf_path).name} -> {Path(generated_html_path).name}")

        verification_result = {
            "original_file": Path(original_pdf_path).name,
            "generated_file": Path(generated_html_path).name,
            "status": "pending",
            "errors": [],
            "warnings": [],
            "corrections": [],
            "statistics": {},
            "recommendations": []
        }

        try:
            # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¹„êµ
            original_text = self._extract_text_from_data(extracted_data)
            generated_text = self._extract_text_from_html(generated_html_path)

            # 2. í…ìŠ¤íŠ¸ ì˜¤ë¥˜ ê²€ì¦
            text_errors = self._check_text_errors(original_text, generated_text)
            verification_result["errors"].extend(text_errors)

            # 3. OCR ì˜¤ë¥˜ ê²€ì¦
            ocr_errors = self._check_ocr_errors(generated_text)
            verification_result["errors"].extend(ocr_errors)

            # 4. ì¤‘ìš” í‚¤ì›Œë“œ ê²€ì¦
            missing_keywords = self._check_critical_keywords(generated_text)
            if missing_keywords:
                verification_result["warnings"].append({
                    "type": "missing_keywords",
                    "keywords": missing_keywords,
                    "message": f"ì¤‘ìš” í‚¤ì›Œë“œ ëˆ„ë½: {', '.join(missing_keywords)}"
                })

            # 5. êµ¬ì¡° ê²€ì¦
            structure_issues = self._verify_structure(extracted_data)
            verification_result["warnings"].extend(structure_issues)

            # 6. ë§í¬ ê²€ì¦
            link_issues = self._verify_links(extracted_data)
            verification_result["warnings"].extend(link_issues)

            # 7. í†µê³„
            verification_result["statistics"] = {
                "total_errors": len(verification_result["errors"]),
                "total_warnings": len(verification_result["warnings"]),
                "ocr_accuracy": self._calculate_accuracy(original_text, generated_text),
                "text_length_original": len(original_text),
                "text_length_generated": len(generated_text),
                "similarity_score": self._calculate_similarity(original_text, generated_text)
            }

            # 8. ìë™ ìˆ˜ì • ì œì•ˆ
            verification_result["corrections"] = self._generate_corrections(
                verification_result["errors"]
            )

            # 9. ìµœì¢… ìƒíƒœ
            if len(verification_result["errors"]) == 0:
                verification_result["status"] = "passed"
                verification_result["recommendations"].append("ê²€ì¦ í†µê³¼! ê²°ê³¼ë¬¼ì´ ì™„ë²½í•©ë‹ˆë‹¤.")
            elif len(verification_result["errors"]) <= 5:
                verification_result["status"] = "warning"
                verification_result["recommendations"].append("ê²½ë¯¸í•œ ì˜¤ë¥˜ ë°œê²¬. ìë™ ìˆ˜ì • ê°€ëŠ¥.")
            else:
                verification_result["status"] = "failed"
                verification_result["recommendations"].append("ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œê²¬. ì¬ë³€í™˜ ê¶Œì¥.")

            logger.info(f"ê²€ì¦ ì™„ë£Œ: {verification_result['status']} "
                       f"(ì˜¤ë¥˜: {verification_result['statistics']['total_errors']}, "
                       f"ê²½ê³ : {verification_result['statistics']['total_warnings']})")

            return verification_result

        except Exception as e:
            logger.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            verification_result["status"] = "error"
            verification_result["errors"].append({
                "type": "system_error",
                "message": f"ê²€ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}"
            })
            return verification_result

    def _extract_text_from_data(self, extracted_data: Dict[str, Any]) -> str:
        """ì¶”ì¶œëœ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        texts = []
        for page in extracted_data.get("pages", []):
            texts.append(page.get("text", ""))
        return "\n".join(texts)

    def _extract_text_from_html(self, html_path: str) -> str:
        """HTML íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            with open(html_path, 'r', encoding='utf-8') as f:
                html_content = f.read()

            # ê°„ë‹¨í•œ HTML íƒœê·¸ ì œê±°
            text = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL)
            text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL)
            text = re.sub(r'<[^>]+>', '', text)
            text = re.sub(r'\s+', ' ', text).strip()

            return text

        except Exception as e:
            logger.error(f"HTML í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return ""

    def _check_text_errors(self, original: str, generated: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ì˜¤ë¥˜ í™•ì¸"""
        errors = []

        # ê¸¸ì´ ì°¨ì´ê°€ ë„ˆë¬´ í¬ë©´ ê²½ê³ 
        length_diff = abs(len(original) - len(generated)) / max(len(original), 1)
        if length_diff > 0.3:  # 30% ì´ìƒ ì°¨ì´
            errors.append({
                "type": "text_length_mismatch",
                "severity": "high",
                "message": f"í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶ˆì¼ì¹˜ (ì°¨ì´: {length_diff:.1%})",
                "original_length": len(original),
                "generated_length": len(generated)
            })

        return errors

    def _check_ocr_errors(self, text: str) -> List[Dict]:
        """ì¼ë°˜ì ì¸ OCR ì˜¤ë¥˜ í™•ì¸"""
        errors = []

        for wrong, correct in self.common_ocr_errors.items():
            if wrong in text and correct not in text:
                errors.append({
                    "type": "ocr_error",
                    "severity": "medium",
                    "wrong_text": wrong,
                    "correct_text": correct,
                    "message": f"OCR ì˜¤ë¥˜ ë°œê²¬: '{wrong}' â†’ '{correct}'ë¡œ ìˆ˜ì • í•„ìš”"
                })

        return errors

    def _check_critical_keywords(self, text: str) -> List[str]:
        """ì¤‘ìš” í‚¤ì›Œë“œ ëˆ„ë½ í™•ì¸"""
        missing = []
        text_lower = text.lower()

        for keyword in self.critical_keywords:
            if keyword.lower() not in text_lower:
                missing.append(keyword)

        return missing

    def _verify_structure(self, extracted_data: Dict[str, Any]) -> List[Dict]:
        """êµ¬ì¡° ê²€ì¦"""
        warnings = []
        structured = extracted_data.get("structured_data", {})

        # í›„ë³´ì ì •ë³´ í™•ì¸
        if not structured.get("candidate_name"):
            warnings.append({
                "type": "missing_candidate_name",
                "message": "í›„ë³´ì ì´ë¦„ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤"
            })

        # ê³µì•½ í™•ì¸
        core_pledges = structured.get("core_pledges", [])
        if len(core_pledges) != 6:
            warnings.append({
                "type": "pledge_count_mismatch",
                "message": f"í•µì‹¬ê³µì•½ ê°œìˆ˜ ë¶ˆì¼ì¹˜ (ì˜ˆìƒ: 6ê°œ, ì‹¤ì œ: {len(core_pledges)}ê°œ)"
            })

        return warnings

    def _verify_links(self, extracted_data: Dict[str, Any]) -> List[Dict]:
        """ë§í¬ ê²€ì¦"""
        warnings = []
        structured = extracted_data.get("structured_data", {})
        contact_info = structured.get("contact_info", "")

        # SNS ë§í¬ íŒ¨í„´ í™•ì¸
        patterns = {
            "facebook": r'facebook\.com/[\w.]+',
            "instagram": r'@[\w.]+',
            "blog": r'blog\.naver\.com/[\w]+'
        }

        for platform, pattern in patterns.items():
            if pattern in contact_info or re.search(pattern, contact_info):
                # ë§í¬ ì¡´ì¬í•˜ì§€ë§Œ í´ë¦­ ê°€ëŠ¥í•œì§€ í™•ì¸ í•„ìš”
                pass
            else:
                warnings.append({
                    "type": "missing_sns_link",
                    "platform": platform,
                    "message": f"{platform} ë§í¬ê°€ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
                })

        return warnings

    def _calculate_accuracy(self, original: str, generated: str) -> float:
        """OCR ì •í™•ë„ ê³„ì‚°"""
        if not original or not generated:
            return 0.0

        matcher = SequenceMatcher(None, original, generated)
        return matcher.ratio() * 100

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not text1 or not text2:
            return 0.0

        matcher = SequenceMatcher(None, text1.lower(), text2.lower())
        return matcher.ratio() * 100

    def _generate_corrections(self, errors: List[Dict]) -> List[Dict]:
        """ìë™ ìˆ˜ì • ì œì•ˆ ìƒì„±"""
        corrections = []

        for error in errors:
            if error.get("type") == "ocr_error":
                corrections.append({
                    "action": "replace_text",
                    "from": error["wrong_text"],
                    "to": error["correct_text"],
                    "confidence": "high"
                })

        return corrections

    def apply_corrections(
        self,
        html_path: str,
        corrections: List[Dict]
    ) -> bool:
        """ìë™ ìˆ˜ì • ì ìš©"""
        try:
            with open(html_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content

            for correction in corrections:
                if correction["action"] == "replace_text":
                    content = content.replace(
                        correction["from"],
                        correction["to"]
                    )

            # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ íŒŒì¼ ì—…ë°ì´íŠ¸
            if content != original_content:
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(content)

                logger.info(f"ìë™ ìˆ˜ì • ì ìš© ì™„ë£Œ: {Path(html_path).name}")
                return True
            else:
                logger.info("ì ìš©í•  ìˆ˜ì •ì‚¬í•­ ì—†ìŒ")
                return False

        except Exception as e:
            logger.error(f"ìë™ ìˆ˜ì • ì ìš© ì‹¤íŒ¨: {str(e)}", exc_info=True)
            return False


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_verification_system = None

def get_verification_system() -> VerificationSystem:
    """ê²€ì¦ ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _verification_system
    if _verification_system is None:
        _verification_system = VerificationSystem()
    return _verification_system


class ChurchBulletinVerifier:
    """êµíšŒ ì£¼ë³´ ì „ìš© ê²€ì¦ ì‹œìŠ¤í…œ - ì›ë³¸ PDFì™€ ê²°ê³¼ë¬¼ ë¹„êµ"""

    def __init__(self):
        # êµíšŒ ì£¼ë³´ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” OCR ì˜¤ë¥˜ íŒ¨í„´
        self.common_ocr_errors = {
            "ì˜ˆë°°": "ì˜ˆë°°",
            "ì°¬ì†¡": "ì°¬ì†¡",
            "ê¸°ë„": "ê¸°ë„",
            "ë§ì”€": "ë§ì”€",
            "í—Œê¸ˆ": "í—Œê¸ˆ",
            "ì¶•ë„": "ì¶•ë„",
            "ì„±ê²½ë´‰ë…": "ì„±ê²½ë´‰ë…",
        }

        # êµíšŒë³„ ì¤‘ìš” í‚¤ì›Œë“œ
        self.church_keywords = {
            "ëª…ì„±êµíšŒ": {
                "required": ["ê¹€ì‚¼í™˜", "ê¹€í•˜ë‚˜", "ì˜ˆë°°", "ì°¬ì†¡"],
                "forbidden": ["ì˜¤ëŠ˜ì˜ ë§ì”€"],  # ëª…ì„±êµíšŒì—ëŠ” ì´ ì„¹ì…˜ì´ ì—†ìŒ
            }
        }

    def verify_church_bulletin(
        self,
        original_pdf_path: str,
        generated_html_path: str,
        extracted_data: Dict[str, Any],
        church_name: str = ""
    ) -> Dict[str, Any]:
        """
        êµíšŒ ì£¼ë³´ ë³€í™˜ ê²°ê³¼ ê²€ì¦

        Args:
            original_pdf_path: ì›ë³¸ PDF íŒŒì¼ ê²½ë¡œ
            generated_html_path: ìƒì„±ëœ HTML íŒŒì¼ ê²½ë¡œ
            extracted_data: OCRë¡œ ì¶”ì¶œëœ ë°ì´í„°
            church_name: êµíšŒëª…

        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"êµíšŒ ì£¼ë³´ ê²€ì¦ ì‹œì‘: {Path(original_pdf_path).name}")

        result = {
            "original_file": Path(original_pdf_path).name,
            "generated_file": Path(generated_html_path).name,
            "church_name": church_name,
            "status": "pending",
            "errors": [],
            "warnings": [],
            "info": [],
            "statistics": {},
            "comparison": {
                "missing_in_html": [],  # PDFì—ëŠ” ìˆì§€ë§Œ HTMLì— ì—†ëŠ” ë‚´ìš©
                "extra_in_html": [],     # PDFì—ëŠ” ì—†ì§€ë§Œ HTMLì— ì¶”ê°€ëœ ë‚´ìš© (í™˜ê°)
                "mismatched": []         # ë¶ˆì¼ì¹˜ ë‚´ìš©
            }
        }

        try:
            # 1. ì›ë³¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
            original_text = self._extract_pdf_text(original_pdf_path)
            if not original_text:
                original_text = self._get_text_from_extracted_data(extracted_data)

            # 2. ìƒì„±ëœ HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            html_text = self._extract_html_text(generated_html_path)

            # 3. í•µì‹¬ ì •ë³´ ë¹„êµ
            comparison = self._compare_key_information(
                original_text, html_text, church_name
            )
            result["comparison"] = comparison

            # 4. êµíšŒë³„ íŠ¹ìˆ˜ ê²€ì¦
            church_specific = self._verify_church_specific(
                html_text, church_name
            )
            result["errors"].extend(church_specific.get("errors", []))
            result["warnings"].extend(church_specific.get("warnings", []))

            # 5. í™˜ê°(Hallucination) ê²€ì‚¬ - HTMLì—ë§Œ ìˆê³  PDFì— ì—†ëŠ” ë‚´ìš©
            hallucinations = self._check_hallucinations(original_text, html_text)
            if hallucinations:
                result["errors"].extend(hallucinations)

            # 6. ëˆ„ë½ ê²€ì‚¬ - PDFì— ìˆì§€ë§Œ HTMLì— ì—†ëŠ” ì¤‘ìš” ë‚´ìš©
            missing = self._check_missing_content(original_text, html_text, church_name)
            if missing:
                result["warnings"].extend(missing)

            # 7. í†µê³„ ê³„ì‚°
            result["statistics"] = {
                "original_length": len(original_text),
                "html_length": len(html_text),
                "similarity_score": self._calculate_similarity(original_text, html_text),
                "total_errors": len(result["errors"]),
                "total_warnings": len(result["warnings"]),
                "hallucination_count": len([e for e in result["errors"] if e.get("type") == "hallucination"]),
                "missing_count": len([w for w in result["warnings"] if w.get("type") == "missing_content"])
            }

            # 8. ìµœì¢… ìƒíƒœ ê²°ì •
            if len(result["errors"]) == 0 and len(result["warnings"]) <= 2:
                result["status"] = "passed"
                result["info"].append("âœ… ê²€ì¦ í†µê³¼! ì›ë³¸ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            elif len(result["errors"]) == 0:
                result["status"] = "warning"
                result["info"].append("âš ï¸ ê²½ë¯¸í•œ ê²½ê³ ê°€ ìˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            else:
                result["status"] = "failed"
                result["info"].append("âŒ ì˜¤ë¥˜ ë°œê²¬! ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

            logger.info(f"êµíšŒ ì£¼ë³´ ê²€ì¦ ì™„ë£Œ: {result['status']} "
                       f"(ì˜¤ë¥˜: {result['statistics']['total_errors']}, "
                       f"ê²½ê³ : {result['statistics']['total_warnings']})")

            return result

        except Exception as e:
            logger.error(f"êµíšŒ ì£¼ë³´ ê²€ì¦ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            result["status"] = "error"
            result["errors"].append({
                "type": "system_error",
                "message": f"ê²€ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}"
            })
            return result

    def _extract_pdf_text(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            import fitz
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text() + "\n"
            doc.close()
            return text.strip()
        except Exception as e:
            logger.warning(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def _get_text_from_extracted_data(self, extracted_data: Dict) -> str:
        """ì¶”ì¶œëœ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        texts = []
        for page in extracted_data.get("pages", []):
            texts.append(page.get("text", ""))
        return "\n".join(texts)

    def _extract_html_text(self, html_path: str) -> str:
        """HTMLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (íƒœê·¸ ì œê±°)"""
        try:
            with open(html_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # script, style íƒœê·¸ ì œê±°
            content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL)
            content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL)
            # HTML íƒœê·¸ ì œê±°
            content = re.sub(r'<[^>]+>', ' ', content)
            # ì—°ì† ê³µë°± ì •ë¦¬
            content = re.sub(r'\s+', ' ', content).strip()

            return content
        except Exception as e:
            logger.error(f"HTML í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def _compare_key_information(
        self,
        original: str,
        html: str,
        church_name: str
    ) -> Dict[str, List]:
        """í•µì‹¬ ì •ë³´ ë¹„êµ"""
        comparison = {
            "missing_in_html": [],
            "extra_in_html": [],
            "mismatched": []
        }

        # ì£¼ìš” ì¶”ì¶œ ëŒ€ìƒ íŒ¨í„´
        patterns = {
            "ë‚ ì§œ": r'\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼',
            "ì„±ê²½êµ¬ì ˆ": r'[ê°€-í£]+\s*\d+[:\s]*\d+[-~\d]*',
            "ì°¬ì†¡ê°€": r'ì°¬ì†¡ê°€?\s*\d+ì¥',
            "ì‹œê°„": r'\d{1,2}[:\s]*\d{2}',
        }

        for name, pattern in patterns.items():
            original_matches = set(re.findall(pattern, original))
            html_matches = set(re.findall(pattern, html))

            # ì›ë³¸ì—ë§Œ ìˆëŠ” ê²ƒ (ëˆ„ë½)
            missing = original_matches - html_matches
            if missing:
                comparison["missing_in_html"].append({
                    "type": name,
                    "values": list(missing)
                })

            # HTMLì—ë§Œ ìˆëŠ” ê²ƒ (ì¶”ê°€ë¨ - ì£¼ì˜ í•„ìš”)
            extra = html_matches - original_matches
            if extra:
                comparison["extra_in_html"].append({
                    "type": name,
                    "values": list(extra)
                })

        return comparison

    def _verify_church_specific(self, html_text: str, church_name: str) -> Dict:
        """êµíšŒë³„ íŠ¹ìˆ˜ ê²€ì¦"""
        result = {"errors": [], "warnings": []}

        if church_name not in self.church_keywords:
            return result

        config = self.church_keywords[church_name]

        # í•„ìˆ˜ í‚¤ì›Œë“œ í™•ì¸
        for keyword in config.get("required", []):
            if keyword not in html_text:
                result["warnings"].append({
                    "type": "missing_required_keyword",
                    "keyword": keyword,
                    "message": f"í•„ìˆ˜ í‚¤ì›Œë“œ '{keyword}'ê°€ ê²°ê³¼ë¬¼ì— ì—†ìŠµë‹ˆë‹¤"
                })

        # ê¸ˆì§€ í‚¤ì›Œë“œ í™•ì¸ (í•´ë‹¹ êµíšŒì— ì—†ì–´ì•¼ í•  ë‚´ìš©)
        for keyword in config.get("forbidden", []):
            if keyword in html_text:
                result["errors"].append({
                    "type": "forbidden_content",
                    "keyword": keyword,
                    "message": f"'{keyword}'ëŠ” {church_name}ì— ì—†ì–´ì•¼ í•  ë‚´ìš©ì…ë‹ˆë‹¤"
                })

        return result

    def _check_hallucinations(self, original: str, html: str) -> List[Dict]:
        """í™˜ê°(Hallucination) ê²€ì‚¬ - HTMLì—ë§Œ ìˆëŠ” ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë‚´ìš©"""
        errors = []

        # ì›ë³¸ì— ì—†ëŠ” ëª©ì‚¬ ì´ë¦„ì´ HTMLì— ìˆëŠ”ì§€ ê²€ì‚¬
        # ì£¼ìš” íŒ¨í„´: "OOO ëª©ì‚¬", "OOO ì „ë„ì‚¬" ë“±
        html_names = set(re.findall(r'([ê°€-í£]{2,4})\s*(?:ëª©ì‚¬|ì „ë„ì‚¬|ì¥ë¡œ|ê¶Œì‚¬)', html))
        original_names = set(re.findall(r'([ê°€-í£]{2,4})\s*(?:ëª©ì‚¬|ì „ë„ì‚¬|ì¥ë¡œ|ê¶Œì‚¬)', original))

        hallucinated_names = html_names - original_names
        for name in hallucinated_names:
            # í”„ë¦¬ì…‹ì—ì„œ ì˜¨ ì´ë¦„ì€ ì œì™¸ (ê¹€ì‚¼í™˜, ê¹€í•˜ë‚˜ ë“±)
            if name not in ["ê¹€ì‚¼í™˜", "ê¹€í•˜ë‚˜"]:
                errors.append({
                    "type": "hallucination",
                    "severity": "high",
                    "content": f"{name}",
                    "message": f"ì›ë³¸ì— ì—†ëŠ” ì´ë¦„ '{name}'ì´(ê°€) HTMLì— ìˆìŠµë‹ˆë‹¤ - í™˜ê° ì˜ì‹¬"
                })

        return errors

    def _check_missing_content(
        self,
        original: str,
        html: str,
        church_name: str
    ) -> List[Dict]:
        """ëˆ„ë½ëœ ì¤‘ìš” ë‚´ìš© ê²€ì‚¬"""
        warnings = []

        # ì›ë³¸ì˜ ì£¼ìš” ìˆ«ì/ì‹œê°„ ì •ë³´ê°€ HTMLì— ìˆëŠ”ì§€ í™•ì¸
        original_times = set(re.findall(r'(\d{1,2}:\d{2})', original))
        html_times = set(re.findall(r'(\d{1,2}:\d{2})', html))

        missing_times = original_times - html_times
        if missing_times:
            warnings.append({
                "type": "missing_content",
                "category": "ì‹œê°„ì •ë³´",
                "missing": list(missing_times),
                "message": f"ì›ë³¸ì˜ ì‹œê°„ ì •ë³´ {missing_times}ê°€ ëˆ„ë½ë¨"
            })

        return warnings

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not text1 or not text2:
            return 0.0

        # ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        t1 = re.sub(r'\s+', '', text1.lower())
        t2 = re.sub(r'\s+', '', text2.lower())

        matcher = SequenceMatcher(None, t1, t2)
        return round(matcher.ratio() * 100, 2)

    def generate_report(self, result: Dict) -> str:
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        lines = [
            "=" * 60,
            "ğŸ“‹ êµíšŒ ì£¼ë³´ ê²€ì¦ ë¦¬í¬íŠ¸",
            "=" * 60,
            f"êµíšŒ: {result.get('church_name', 'N/A')}",
            f"ì›ë³¸: {result.get('original_file', 'N/A')}",
            f"ê²°ê³¼: {result.get('generated_file', 'N/A')}",
            f"ìƒíƒœ: {result.get('status', 'N/A').upper()}",
            "",
            "ğŸ“Š í†µê³„:",
            f"  - ìœ ì‚¬ë„: {result.get('statistics', {}).get('similarity_score', 0)}%",
            f"  - ì˜¤ë¥˜: {result.get('statistics', {}).get('total_errors', 0)}ê°œ",
            f"  - ê²½ê³ : {result.get('statistics', {}).get('total_warnings', 0)}ê°œ",
            f"  - í™˜ê°: {result.get('statistics', {}).get('hallucination_count', 0)}ê°œ",
            f"  - ëˆ„ë½: {result.get('statistics', {}).get('missing_count', 0)}ê°œ",
        ]

        if result.get("errors"):
            lines.append("")
            lines.append("âŒ ì˜¤ë¥˜:")
            for err in result["errors"]:
                lines.append(f"  - [{err.get('type')}] {err.get('message')}")

        if result.get("warnings"):
            lines.append("")
            lines.append("âš ï¸ ê²½ê³ :")
            for warn in result["warnings"]:
                lines.append(f"  - [{warn.get('type')}] {warn.get('message')}")

        if result.get("info"):
            lines.append("")
            for info in result["info"]:
                lines.append(info)

        lines.append("=" * 60)
        return "\n".join(lines)


# êµíšŒ ì£¼ë³´ ê²€ì¦ ì‹±ê¸€í†¤
_church_verifier = None

def get_church_bulletin_verifier() -> ChurchBulletinVerifier:
    """êµíšŒ ì£¼ë³´ ê²€ì¦ ì‹œìŠ¤í…œ ì‹±ê¸€í†¤"""
    global _church_verifier
    if _church_verifier is None:
        _church_verifier = ChurchBulletinVerifier()
    return _church_verifier
