"""
StudySnap Backend - PDF to Mobile HTML Converter
FastAPI ê¸°ë°˜ ë°±ì—”ë“œ ì„œë²„
"""

import os
import uuid
import shutil
import logging
import zipfile
import io
from datetime import datetime
from pathlib import Path
from typing import Optional, List

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from starlette.middleware.base import BaseHTTPMiddleware
from urllib.parse import unquote, quote
from dotenv import load_dotenv

from pdf_converter import PDFConverter
from html_generator import HTMLGenerator
from learning_system import get_learning_system
from universal_parser import get_universal_parser
from template_engine import get_template_engine
from localization import get_localization_manager
from verification_system import get_verification_system
from intelligent_layout_engine import get_layout_engine

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
learning_system = get_learning_system()
universal_parser = get_universal_parser()
template_engine = get_template_engine()
localization_manager = get_localization_manager()
verification_system = get_verification_system()
layout_engine = get_layout_engine()

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="StudySnap API",
    description="PDFë¥¼ ëª¨ë°”ì¼ ìµœì í™” HTMLë¡œ ë³€í™˜í•˜ëŠ” API",
    version="1.0.0"
)

# ============================================
# í•œê¸€ URL ì¸ì½”ë”© ë¯¸ë“¤ì›¨ì–´
# ============================================
class KoreanURLMiddleware(BaseHTTPMiddleware):
    """
    í•œê¸€ URLì„ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•˜ëŠ” ë¯¸ë“¤ì›¨ì–´
    Windowsì—ì„œ ì™¸ë¶€ ì ‘ì† ì‹œ í•œê¸€ ê¹¨ì§ ë¬¸ì œ í•´ê²°
    """
    async def dispatch(self, request: Request, call_next):
        # ì›ë³¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        original_path = request.scope.get('path', '')

        # URL ë””ì½”ë”© ì‹œë„ (ì´ë¯¸ ë””ì½”ë”©ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€)
        try:
            # UTF-8ë¡œ URL ë””ì½”ë”©
            decoded_path = unquote(original_path, encoding='utf-8')

            # CP949ë¡œ ì˜ëª» ì¸ì½”ë”©ëœ ê²½ìš° ë³µêµ¬ ì‹œë„
            if decoded_path != original_path:
                try:
                    # CP949ë¡œ ì¸ì½”ë”©ëœ ë°”ì´íŠ¸ë¥¼ UTF-8ë¡œ ì¬í•´ì„
                    test_bytes = decoded_path.encode('latin-1')
                    try:
                        # CP949ë¡œ ë””ì½”ë”© ì‹œë„
                        cp949_decoded = test_bytes.decode('cp949')
                        # UTF-8ë¡œ ë‹¤ì‹œ ì¸ì½”ë”©í•˜ì—¬ ì˜¬ë°”ë¥¸ ê²½ë¡œ ìƒì„±
                        decoded_path = cp949_decoded
                        logger.debug(f"CP949 ë³µêµ¬: {original_path} -> {decoded_path}")
                    except (UnicodeDecodeError, UnicodeEncodeError):
                        pass
                except (UnicodeDecodeError, UnicodeEncodeError):
                    pass

            # ê²½ë¡œ ì—…ë°ì´íŠ¸
            request.scope['path'] = decoded_path

        except Exception as e:
            logger.warning(f"URL ë””ì½”ë”© ì‹¤íŒ¨: {original_path} - {e}")

        response = await call_next(request)
        return response

# ë¯¸ë“¤ì›¨ì–´ ë“±ë¡ (ìˆœì„œ ì¤‘ìš”: ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
app.add_middleware(KoreanURLMiddleware)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:5500",
        "http://127.0.0.1:5500",
        "https://studysnap-demo.netlify.app",
        "*"  # ê°œë°œ ì¤‘ì—ëŠ” ëª¨ë“  origin í—ˆìš©
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
UPLOAD_DIR = BASE_DIR / "uploads"
OUTPUT_DIR = BASE_DIR / "outputs"
TEMPLATES_DIR = BASE_DIR / "templates"

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)
TEMPLATES_DIR.mkdir(exist_ok=True)

# ì •ì  íŒŒì¼ ì„œë¹™
STATIC_DIR = BASE_DIR / "static"
STATIC_DIR.mkdir(exist_ok=True)

# static í´ë”ëŠ” StaticFilesë¡œ ì„œë¹™ (ì˜ë¬¸ íŒŒì¼ëª…ë§Œ ìˆìŒ)
app.mount("/static", StaticFiles(directory=str(STATIC_DIR), html=True), name="static")

# outputs í´ë”ëŠ” í•œê¸€ ì§€ì›ì„ ìœ„í•´ ì»¤ìŠ¤í…€ ë¼ìš°í„°ë¡œ ì²˜ë¦¬ (ì•„ë˜ serve_outputs_file ì°¸ì¡°)
# app.mount("/outputs", StaticFiles(directory=str(OUTPUT_DIR)), name="outputs")  # ë¹„í™œì„±í™”

# PDF ë³€í™˜ê¸° ë° HTML ìƒì„±ê¸° ì´ˆê¸°í™”
pdf_converter = PDFConverter()
html_generator = HTMLGenerator()


# ============================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================

def cleanup_temp_files(job_id: str = None, keep_outputs: bool = True, cleanup_old_files: bool = False, max_age_hours: int = 24):
    """
    ì„ì‹œ íŒŒì¼ ì •ë¦¬ í•¨ìˆ˜

    Parameters:
    - job_id: íŠ¹ì • ì‘ì—… IDì˜ íŒŒì¼ë§Œ ì‚­ì œ (Noneì´ë©´ ëª¨ë“  ì„ì‹œ íŒŒì¼)
    - keep_outputs: outputs í´ë”ì˜ ìµœì¢… ê²°ê³¼ë¬¼ ìœ ì§€ (ê¸°ë³¸ê°’: True)
    - cleanup_old_files: ì˜¤ë˜ëœ íŒŒì¼ ìë™ ì •ë¦¬ (ê¸°ë³¸ê°’: False)
    - max_age_hours: íŒŒì¼ ë³´ê´€ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ê°’: 24ì‹œê°„)
    """
    deleted_files = []
    from datetime import datetime, timedelta

    try:
        # uploads í´ë” ì •ë¦¬
        if job_id:
            # íŠ¹ì • job_idì˜ íŒŒì¼ë§Œ ì‚­ì œ
            for file_path in UPLOAD_DIR.glob(f"{job_id}_*"):
                try:
                    file_path.unlink()
                    deleted_files.append(str(file_path))
                    logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {file_path.name}")
                except Exception as e:
                    logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path.name}): {str(e)}")

        elif cleanup_old_files:
            # ì˜¤ë˜ëœ íŒŒì¼ ìë™ ì •ë¦¬ (max_age_hours ì´ìƒ ëœ íŒŒì¼)
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)

            for file_path in UPLOAD_DIR.glob("*"):
                if file_path.is_file():
                    try:
                        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
                        file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)

                        if file_mtime < cutoff_time:
                            file_path.unlink()
                            deleted_files.append(str(file_path))
                            logger.info(f"ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ ({max_age_hours}ì‹œê°„ ê²½ê³¼): {file_path.name}")
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path.name}): {str(e)}")

        else:
            # ëª¨ë“  ì„ì‹œ íŒŒì¼ ì‚­ì œ (ìˆ˜ë™ í˜¸ì¶œ ì‹œ)
            for file_path in UPLOAD_DIR.glob("*"):
                if file_path.is_file():
                    try:
                        file_path.unlink()
                        deleted_files.append(str(file_path))
                        logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {file_path.name}")
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path.name}): {str(e)}")

        # outputs í´ë”ëŠ” keep_outputs=Falseì¼ ë•Œë§Œ ì •ë¦¬
        if not keep_outputs:
            if job_id:
                for file_path in OUTPUT_DIR.glob(f"{job_id}_*"):
                    try:
                        file_path.unlink()
                        deleted_files.append(str(file_path))
                        logger.info(f"ì¶œë ¥ íŒŒì¼ ì‚­ì œ: {file_path.name}")
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path.name}): {str(e)}")

            elif cleanup_old_files:
                # ì˜¤ë˜ëœ ì¶œë ¥ íŒŒì¼ë„ ì •ë¦¬ (ì„ íƒì )
                cutoff_time = datetime.now() - timedelta(hours=max_age_hours)

                for file_path in OUTPUT_DIR.glob("*.html"):
                    try:
                        file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)

                        if file_mtime < cutoff_time:
                            file_path.unlink()
                            deleted_files.append(str(file_path))
                            logger.info(f"ì˜¤ë˜ëœ ì¶œë ¥ íŒŒì¼ ì‚­ì œ ({max_age_hours}ì‹œê°„ ê²½ê³¼): {file_path.name}")
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path.name}): {str(e)}")

            else:
                for file_path in OUTPUT_DIR.glob("*"):
                    if file_path.is_file():
                        try:
                            file_path.unlink()
                            deleted_files.append(str(file_path))
                            logger.info(f"ì¶œë ¥ íŒŒì¼ ì‚­ì œ: {file_path.name}")
                        except Exception as e:
                            logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file_path.name}): {str(e)}")

        if deleted_files:
            logger.info(f"ì´ {len(deleted_files)}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")

        return deleted_files

    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return deleted_files


@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "service": "StudySnap API",
        "version": "1.0.0",
        "message": "PDFë¥¼ ëª¨ë°”ì¼ ìµœì í™” HTMLë¡œ ë³€í™˜í•©ë‹ˆë‹¤"
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


# ============================================
# í•œê¸€ íŒŒì¼ëª… ì§€ì› outputs ë¼ìš°í„°
# ============================================
@app.get("/outputs/{file_path:path}")
async def serve_outputs_file(file_path: str, request: Request):
    """
    outputs í´ë”ì˜ íŒŒì¼ì„ í•œê¸€ íŒŒì¼ëª… ì§€ì›í•˜ì—¬ ì„œë¹™
    StaticFilesì˜ í•œê¸€ ì¸ì½”ë”© ë¬¸ì œë¥¼ ìš°íšŒ

    ì˜ˆ: /outputs/ë¯¼ì£¼-ë¥˜ì‚¼ì˜/ë¥˜ì‚¼ì˜_with_images.html
    """
    import mimetypes

    try:
        # URL ë””ì½”ë”© (ë¯¸ë“¤ì›¨ì–´ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
        decoded_path = unquote(file_path, encoding='utf-8')

        # ê²½ë¡œ ë³´ì•ˆ ê²€ì¦
        full_path = OUTPUT_DIR / decoded_path

        try:
            resolved_path = full_path.resolve()
            base_resolved = OUTPUT_DIR.resolve()

            # ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
            if not str(resolved_path).startswith(str(base_resolved)):
                raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")
        except Exception:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not full_path.exists():
            # CP949 ì¸ì½”ë”©ìœ¼ë¡œ ì¬ì‹œë„
            try:
                cp949_path = decoded_path.encode('utf-8').decode('cp949', errors='ignore')
                alt_path = OUTPUT_DIR / cp949_path
                if alt_path.exists():
                    full_path = alt_path
                else:
                    raise HTTPException(status_code=404, detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {decoded_path}")
            except:
                raise HTTPException(status_code=404, detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {decoded_path}")

        if full_path.is_dir():
            raise HTTPException(status_code=400, detail="ë””ë ‰í† ë¦¬ëŠ” ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # MIME íƒ€ì… ê²°ì •
        mime_type, _ = mimetypes.guess_type(str(full_path))
        if mime_type is None:
            mime_type = "application/octet-stream"

        # íŒŒì¼ ë°˜í™˜
        return FileResponse(
            path=str(full_path),
            media_type=mime_type,
            filename=full_path.name,
            headers={
                "Cache-Control": "public, max-age=3600",
                "Content-Disposition": f"inline; filename*=UTF-8''{quote(full_path.name)}"
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì„œë¹™ ì‹¤íŒ¨: {file_path} - {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì„œë¹™ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/convert")
async def convert_pdf(
    file: UploadFile = File(...),
    content_type: str = Form(default="general"),
    title: Optional[str] = Form(default=None),
    exclude_pages: Optional[str] = Form(default=None)
):
    """
    PDF íŒŒì¼ì„ ëª¨ë°”ì¼ ìµœì í™” HTMLë¡œ ë³€í™˜

    - file: PDF íŒŒì¼
    - content_type: ì½˜í…ì¸  ìœ í˜• (lecture, election, church, general)
    - title: ê²°ê³¼ë¬¼ ì œëª© (ì„ íƒì‚¬í•­)
    - exclude_pages: ì œì™¸í•  í˜ì´ì§€ ë²ˆí˜¸ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: "2,3,5")
    """

    # íŒŒì¼ ê²€ì¦
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")

    # íŒŒì¼ í¬ê¸° ì œí•œ (50MB)
    MAX_FILE_SIZE = 50 * 1024 * 1024
    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ëŠ” 50MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ê³ ìœ  ID ìƒì„±
    job_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # íŒŒì¼ ì €ì¥
    original_filename = file.filename
    safe_filename = f"{job_id}_{timestamp}.pdf"
    upload_path = UPLOAD_DIR / safe_filename

    try:
        with open(upload_path, "wb") as f:
            f.write(content)

        # PDF ë³€í™˜ ì²˜ë¦¬
        logger.info(f"[{job_id}] PDF ë³€í™˜ ì‹œì‘: {original_filename} (content_type: {content_type})")

        # ì œì™¸í•  í˜ì´ì§€ ì²˜ë¦¬
        exclude_pages_list = []
        if exclude_pages:
            try:
                exclude_pages_list = [int(p.strip()) for p in exclude_pages.split(',') if p.strip()]
                logger.info(f"[{job_id}] ì œì™¸í•  í˜ì´ì§€: {exclude_pages_list}")
            except ValueError:
                logger.warning(f"[{job_id}] ì˜ëª»ëœ exclude_pages í˜•ì‹: {exclude_pages}")

        # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ
        try:
            extracted_data = pdf_converter.extract_from_pdf(
                str(upload_path),
                content_type=content_type,
                exclude_pages=exclude_pages_list
            )
        except Exception as e:
            logger.error(f"[{job_id}] PDF ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

        if not extracted_data:
            logger.error(f"[{job_id}] PDF ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŒ")
            raise HTTPException(status_code=500, detail="PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

        logger.info(f"[{job_id}] PDF ì¶”ì¶œ ì™„ë£Œ: {extracted_data.get('page_count', 0)}í˜ì´ì§€")

        # 2. HTML ìƒì„±
        result_title = title or Path(original_filename).stem
        output_filename = f"{job_id}_{timestamp}.html"
        output_path = OUTPUT_DIR / output_filename

        try:
            html_content = html_generator.generate_html(
                extracted_data=extracted_data,
                title=result_title,
                content_type=content_type,
                job_id=job_id
            )
        except Exception as e:
            logger.error(f"[{job_id}] HTML ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"HTML ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        logger.info(f"[{job_id}] ë³€í™˜ ì™„ë£Œ: {output_filename}")

        # 3. ìë™ ê²€ì¦ ì‹œìŠ¤í…œ ì‹¤í–‰
        verification_result = None
        try:
            logger.info(f"[{job_id}] ìë™ ê²€ì¦ ì‹œì‘")
            verification_result = verification_system.verify_conversion(
                original_pdf_path=str(upload_path),
                generated_html_path=str(output_path),
                extracted_data=extracted_data
            )

            logger.info(f"[{job_id}] ê²€ì¦ ì™„ë£Œ: {verification_result['status']} "
                       f"(ì˜¤ë¥˜: {verification_result['statistics']['total_errors']}, "
                       f"ê²½ê³ : {verification_result['statistics']['total_warnings']})")

            # ìë™ ìˆ˜ì • ì ìš©
            if verification_result.get("corrections"):
                logger.info(f"[{job_id}] ìë™ ìˆ˜ì • ì ìš© ì¤‘ ({len(verification_result['corrections'])}ê°œ)")
                correction_applied = verification_system.apply_corrections(
                    str(output_path),
                    verification_result["corrections"]
                )
                if correction_applied:
                    logger.info(f"[{job_id}] ìë™ ìˆ˜ì • ì™„ë£Œ")
                    verification_result["auto_corrected"] = True

        except Exception as e:
            logger.error(f"[{job_id}] ê²€ì¦ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {str(e)}", exc_info=True)
            verification_result = {
                "status": "error",
                "message": f"ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
            }

        # 4. ì„ì‹œ íŒŒì¼ ì •ë¦¬ (uploads í´ë”ì˜ ì›ë³¸ PDF)
        try:
            cleanup_temp_files(job_id=job_id, keep_outputs=True)
            logger.info(f"[{job_id}] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"[{job_id}] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {str(e)}")

        # í•™ìŠµ ì‹œìŠ¤í…œì— ë³€í™˜ ê¸°ë¡
        try:
            learning_system.log_conversion(job_id, {
                "filename": original_filename,
                "content_type": content_type,
                "page_count": extracted_data.get("page_count", 0),
                "is_image_based": extracted_data.get("is_image_based", False),
                "ocr_used": extracted_data.get("ocr_used", False),
                "processing_time": 0,  # TODO: ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
                "structured_data": extracted_data.get("structured_data", {})
            })
        except Exception as e:
            logger.error(f"í•™ìŠµ ë°ì´í„° ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")

        # ê²°ê³¼ URL ìƒì„±
        result_url = f"/outputs/{output_filename}"

        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "success": True,
            "job_id": job_id,
            "message": "ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "result": {
                "url": result_url,
                "filename": output_filename,
                "original_filename": original_filename,
                "content_type": content_type,
                "title": result_title,
                "page_count": extracted_data.get("page_count", 0),
                "created_at": datetime.now().isoformat()
            }
        }

        # ê²€ì¦ ê²°ê³¼ ì¶”ê°€
        if verification_result:
            response_data["verification"] = {
                "status": verification_result.get("status", "unknown"),
                "accuracy": verification_result.get("statistics", {}).get("ocr_accuracy", 0),
                "similarity": verification_result.get("statistics", {}).get("similarity_score", 0),
                "errors": verification_result.get("statistics", {}).get("total_errors", 0),
                "warnings": verification_result.get("statistics", {}).get("total_warnings", 0),
                "auto_corrected": verification_result.get("auto_corrected", False),
                "recommendations": verification_result.get("recommendations", [])
            }

        return JSONResponse(response_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[{job_id}] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    finally:
        # ì—…ë¡œë“œ íŒŒì¼ ì •ë¦¬ (ì„ íƒì )
        # if upload_path.exists():
        #     upload_path.unlink()
        pass


@app.get("/api/result/{job_id}")
async def get_result(job_id: str):
    """ë³€í™˜ ê²°ê³¼ ì¡°íšŒ"""

    # outputs ë””ë ‰í† ë¦¬ì—ì„œ job_idë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ ì°¾ê¸°
    for file_path in OUTPUT_DIR.glob(f"{job_id}_*.html"):
        return FileResponse(
            path=str(file_path),
            media_type="text/html",
            filename=file_path.name
        )

    raise HTTPException(status_code=404, detail="ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")


@app.delete("/api/result/{job_id}")
async def delete_result(job_id: str):
    """ë³€í™˜ ê²°ê³¼ ì‚­ì œ"""

    deleted = False

    # outputs ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì‚­ì œ
    for file_path in OUTPUT_DIR.glob(f"{job_id}_*"):
        file_path.unlink()
        deleted = True

    # uploads ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì‚­ì œ
    for file_path in UPLOAD_DIR.glob(f"{job_id}_*"):
        file_path.unlink()
        deleted = True

    if deleted:
        return {"success": True, "message": "ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}

    raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")


@app.get("/api/content-types")
async def get_content_types():
    """ì§€ì›í•˜ëŠ” ì½˜í…ì¸  ìœ í˜• ëª©ë¡"""
    return {
        "content_types": [
            {
                "id": "lecture",
                "name": "ê°•ì˜ìë£Œ",
                "description": "ìˆ˜ì—… ê°•ì˜ë…¸íŠ¸, í”„ë ˆì  í…Œì´ì…˜ ìë£Œ",
                "icon": "ğŸ“š"
            },
            {
                "id": "election",
                "name": "ì„ ê±° í™ë³´ë¬¼",
                "description": "í›„ë³´ì ì†Œê°œ, ê³µì•½, ì„ ê±° í¬ìŠ¤í„°",
                "icon": "ğŸ—³ï¸"
            },
            {
                "id": "church",
                "name": "êµíšŒ ì£¼ë³´",
                "description": "ì£¼ì¼ ì˜ˆë°° ìˆœì„œ, êµíšŒ ì†Œì‹",
                "icon": "â›ª"
            },
            {
                "id": "general",
                "name": "ì¼ë°˜ ë¬¸ì„œ",
                "description": "ê¸°íƒ€ PDF ë¬¸ì„œ",
                "icon": "ğŸ“„"
            }
        ]
    }


# ============================================
# í•™ìŠµ ì‹œìŠ¤í…œ API ì—”ë“œí¬ì¸íŠ¸
# ============================================

@app.post("/api/feedback")
async def submit_feedback(
    job_id: str = Form(...),
    rating: int = Form(...),
    accuracy: Optional[int] = Form(None),
    completeness: Optional[int] = Form(None),
    issues: Optional[str] = Form(None),
    comment: Optional[str] = Form(None)
):
    """
    ë³€í™˜ ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°± ì œì¶œ

    Parameters:
    - job_id: ë³€í™˜ ì‘ì—… ID
    - rating: ì „ì²´ ë§Œì¡±ë„ (1-5)
    - accuracy: OCR ì •í™•ë„ (1-5)
    - completeness: ì™„ì„±ë„ (1-5)
    - issues: ë°œê²¬ëœ ë¬¸ì œë“¤ (ì½¤ë§ˆë¡œ êµ¬ë¶„)
    - comment: ìƒì„¸ ì½”ë©˜íŠ¸
    """
    try:
        # issues ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        issues_list = [i.strip() for i in issues.split(",")] if issues else []

        feedback_data = {
            "rating": rating,
            "accuracy": accuracy or rating,
            "completeness": completeness or rating,
            "issues": issues_list,
            "comment": comment or "",
            "corrections": {}
        }

        learning_system.log_feedback(job_id, feedback_data)

        return JSONResponse({
            "success": True,
            "message": "í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!",
            "job_id": job_id
        })

    except Exception as e:
        logger.error(f"í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/statistics")
async def get_statistics():
    """ì „ì²´ ë³€í™˜ í†µê³„ ë° í•™ìŠµ ë°ì´í„° ì¡°íšŒ"""
    try:
        stats = learning_system.get_statistics()
        suggestions = learning_system.get_improvement_suggestions()

        return JSONResponse({
            "success": True,
            "statistics": stats,
            "improvement_suggestions": suggestions,
            "generated_at": datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/learning/insights")
async def get_learning_insights():
    """í•™ìŠµ ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ - ê°œì„  ì œì•ˆ ë° íŒ¨í„´ ë¶„ì„"""
    try:
        stats = learning_system.get_statistics()
        suggestions = learning_system.get_improvement_suggestions()

        insights = {
            "summary": {
                "total_conversions": stats.get("total_conversions", 0),
                "feedback_rate": f"{(stats.get('feedback_count', 0) / max(stats.get('total_conversions', 1), 1) * 100):.1f}%",
                "average_rating": f"{stats.get('average_rating', 0):.2f}/5.0",
                "success_rate": f"{stats.get('success_rate', 0):.1f}%"
            },
            "top_content_types": dict(stats.get("content_types", {})),
            "common_issues": dict(stats.get("common_issues", {})),
            "improvement_suggestions": suggestions,
            "system_health": "good" if stats.get("average_rating", 0) >= 4 else "needs_improvement"
        }

        return JSONResponse({
            "success": True,
            "insights": insights,
            "generated_at": datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/learning/export")
async def export_learning_data():
    """í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸° (JSON í˜•ì‹)"""
    try:
        export_filename = f"learning_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        export_path = OUTPUT_DIR / export_filename

        success = learning_system.export_training_data(str(export_path))

        if success:
            return JSONResponse({
                "success": True,
                "message": "í•™ìŠµ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë‚´ë³´ë‚´ì¡ŒìŠµë‹ˆë‹¤",
                "download_url": f"/outputs/{export_filename}",
                "filename": export_filename
            })
        else:
            raise HTTPException(status_code=500, detail="í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}")


# ============================================
# ëŠ¥ë™í˜• AI í•™ìŠµ API (v2.0)
# ============================================

# ëŠ¥ë™í˜• í•™ìŠµ ì—”ì§„ ì´ˆê¸°í™”
try:
    from learning_data.active_learning import get_learning_engine
    active_learning_engine = get_learning_engine()
    logger.info("ëŠ¥ë™í˜• AI í•™ìŠµ ì—”ì§„ ë¡œë“œë¨")
except ImportError as e:
    active_learning_engine = None
    logger.warning(f"ëŠ¥ë™í˜• í•™ìŠµ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")


@app.get("/api/learning/stats")
async def get_active_learning_stats():
    """ëŠ¥ë™í˜• AI í•™ìŠµ í†µê³„ ì¡°íšŒ"""
    try:
        if active_learning_engine is None:
            return JSONResponse({"error": "í•™ìŠµ ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}, status_code=500)

        stats = active_learning_engine.get_learning_stats()
        return JSONResponse(stats)
    except Exception as e:
        logger.error(f"í•™ìŠµ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


@app.post("/api/learning/feedback")
async def submit_learning_feedback(request: Request):
    """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° í•™ìŠµ"""
    try:
        if active_learning_engine is None:
            return JSONResponse({"error": "í•™ìŠµ ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}, status_code=500)

        data = await request.json()

        feedback = active_learning_engine.add_feedback(
            job_id=data.get("job_id", "unknown"),
            rating=data.get("rating", 3),
            feedback_type=data.get("feedback_type", "rating"),
            category=data.get("category", "overall"),
            original_value=data.get("original_value", ""),
            corrected_value=data.get("corrected_value", ""),
            comment=data.get("comment", "")
        )

        logger.info(f"í”¼ë“œë°± ìˆ˜ì‹ : job={data.get('job_id')}, rating={data.get('rating')}")

        return JSONResponse({
            "success": True,
            "message": "í”¼ë“œë°±ì´ ì €ì¥ë˜ê³  í•™ìŠµì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤",
            "feedback_id": feedback.job_id
        })
    except Exception as e:
        logger.error(f"í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


@app.post("/api/learning/html-diff")
async def save_html_diff(request: Request):
    """HTML ë³€ê²½ ë¹„êµ ì €ì¥ ë° íŒ¨í„´ í•™ìŠµ"""
    try:
        if active_learning_engine is None:
            return JSONResponse({"error": "í•™ìŠµ ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}, status_code=500)

        data = await request.json()

        diff = active_learning_engine.save_html_diff(
            job_id=data.get("job_id", "unknown"),
            original_html=data.get("original_html", ""),
            modified_html=data.get("modified_html", "")
        )

        logger.info(f"HTML ë³€ê²½ ì €ì¥: job={data.get('job_id')}, changes={len(diff.changes)}")

        return JSONResponse({
            "success": True,
            "message": f"{len(diff.changes)}ê°œ ë³€ê²½ì  ë¶„ì„, {len(diff.extracted_patterns)}ê°œ íŒ¨í„´ ì¶”ì¶œë¨",
            "changes_count": len(diff.changes),
            "patterns_count": len(diff.extracted_patterns)
        })
    except Exception as e:
        logger.error(f"HTML diff ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


@app.get("/api/learning/report")
async def get_learning_report():
    """AI í•™ìŠµ ê°œì„  ë¦¬í¬íŠ¸"""
    try:
        if active_learning_engine is None:
            return JSONResponse({"error": "í•™ìŠµ ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}, status_code=500)

        report = active_learning_engine.get_improvement_report()
        stats = active_learning_engine.get_learning_stats()

        return JSONResponse({
            "success": True,
            "report": report,
            "stats": stats
        })
    except Exception as e:
        logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


@app.get("/api/learning/status")
async def get_learning_status():
    """
    í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ API

    - ë³€í™˜ ê¸°ë¡ ìˆ˜
    - í”¼ë“œë°± ìˆ˜
    - í•™ìŠµëœ ê·œì¹™ ìˆ˜
    - ì •ë‹¹ë³„/í›„ë³´ìœ í˜•ë³„ í†µê³„
    """
    try:
        result = {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "engines": {
                "active_learning": active_learning_engine is not None,
                "learning_system": learning_system is not None
            },
            "stats": {}
        }

        # ëŠ¥ë™í˜• í•™ìŠµ ì—”ì§„ í†µê³„
        if active_learning_engine is not None:
            stats = active_learning_engine.get_learning_stats()
            result["stats"]["active_learning"] = {
                "total_feedbacks": stats.get("total_feedbacks", 0),
                "corrections_count": stats.get("corrections_count", 0),
                "rules_generated": stats.get("rules_generated", 0),
                "rules_improved": stats.get("rules_improved", 0),
                "active_rules": stats.get("active_rules", 0),
                "high_confidence_rules": stats.get("high_confidence_rules", 0),
                "conversion_count": stats.get("conversion_count", 0),
                "party_stats": stats.get("party_stats", {}),
                "candidate_type_stats": stats.get("candidate_type_stats", {})
            }

        # ê¸°ì¡´ í•™ìŠµ ì‹œìŠ¤í…œ í†µê³„
        if learning_system is not None:
            try:
                ls_stats = learning_system.get_stats()
                result["stats"]["learning_system"] = ls_stats
            except Exception:
                result["stats"]["learning_system"] = {"status": "error"}

        # í•™ìŠµ ë°ì´í„° íŒŒì¼ í™•ì¸
        learning_data_dir = BASE_DIR / "learning_data"
        if learning_data_dir.exists():
            files_info = {}
            for file in learning_data_dir.glob("*.json*"):
                try:
                    files_info[file.name] = {
                        "size_kb": round(file.stat().st_size / 1024, 2),
                        "modified": datetime.fromtimestamp(file.stat().st_mtime).isoformat()
                    }
                except Exception:
                    pass
            result["learning_files"] = files_info

        return JSONResponse(result)

    except Exception as e:
        logger.error(f"í•™ìŠµ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


# ============================================
# ë²”ìš© ë³€í™˜ ì‹œìŠ¤í…œ API
# ============================================

@app.get("/api/formats/supported")
async def get_supported_formats():
    """ì§€ì›í•˜ëŠ” ëª¨ë“  íŒŒì¼ í˜•ì‹ ì¡°íšŒ"""
    try:
        formats = universal_parser.get_supported_formats()
        templates = template_engine.list_templates()

        return JSONResponse({
            "success": True,
            "supported_formats": formats,
            "output_templates": templates,
            "total_formats": sum(len(v) for v in formats.values()),
            "total_templates": len(templates)
        })

    except Exception as e:
        logger.error(f"í˜•ì‹ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/convert/universal")
async def universal_convert(
    file: UploadFile = File(...),
    content_type: str = Form("general"),
    output_format: str = Form("mobile_html"),
    title: Optional[str] = Form(None),
    language: str = Form("ko"),
    custom_options: Optional[str] = Form(None)
):
    """
    ë²”ìš© ë¬¸ì„œ ë³€í™˜ API - ëª¨ë“  íŒŒì¼ í˜•ì‹ ì§€ì›

    Parameters:
    - file: ë³€í™˜í•  íŒŒì¼ (PDF, Word, PowerPoint, Excel, ì´ë¯¸ì§€ ë“±)
    - content_type: ì½˜í…ì¸  íƒ€ì… (election, lecture, church, general)
    - output_format: ì¶œë ¥ í…œí”Œë¦¿ (mobile_html, json, markdown, print_html ë“±)
    - title: ë¬¸ì„œ ì œëª©
    - language: ì–¸ì–´ (ko, en, ja, zh)
    - custom_options: ì»¤ìŠ¤í…€ ì˜µì…˜ (JSON ë¬¸ìì—´)
    """
    job_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    try:
        # íŒŒì¼ ì €ì¥
        content = await file.read()
        original_filename = file.filename
        file_extension = Path(original_filename).suffix
        safe_filename = f"{job_id}_{timestamp}{file_extension}"
        upload_path = UPLOAD_DIR / safe_filename

        with open(upload_path, "wb") as f:
            f.write(content)

        logger.info(f"[{job_id}] ë²”ìš© ë³€í™˜ ì‹œì‘: {original_filename} (ì¶œë ¥: {output_format})")

        # ë²”ìš© íŒŒì„œë¡œ ë¬¸ì„œ íŒŒì‹±
        parse_options = {
            'content_type': content_type,
            'output_format': output_format,
            'language': language
        }

        if custom_options:
            try:
                parse_options.update(json.loads(custom_options))
            except:
                pass

        extracted_data = universal_parser.parse_document(str(upload_path), parse_options)

        if 'error' in extracted_data:
            raise HTTPException(status_code=400, detail=extracted_data['error'])

        logger.info(f"[{job_id}] íŒŒì‹± ì™„ë£Œ: {extracted_data.get('parser_used', 'Unknown')} ì‚¬ìš©")

        # ì¶œë ¥ ìƒì„±
        result_title = title or Path(original_filename).stem
        output_filename = f"{job_id}_{timestamp}.html"
        output_path = OUTPUT_DIR / output_filename

        # í…œí”Œë¦¿ìœ¼ë¡œ ë Œë”ë§
        template_data = {
            'title': result_title,
            'language': language,
            'content': extracted_data.get('pages', [{}])[0].get('text', ''),
            'pages': extracted_data.get('pages', []),
            'data': extracted_data,
            'metadata': extracted_data.get('metadata', {})
        }

        output_content = template_engine.render(output_format, template_data)

        if output_content:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(output_content)
        else:
            # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ HTML ìƒì„±ê¸° ì‚¬ìš©
            html_content = html_generator.generate_html(
                extracted_data=extracted_data,
                title=result_title,
                content_type=content_type,
                job_id=job_id
            )
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(html_content)

        # í•™ìŠµ ë°ì´í„° ê¸°ë¡
        try:
            learning_system.log_conversion(job_id, {
                "filename": original_filename,
                "content_type": content_type,
                "page_count": extracted_data.get("page_count", 0),
                "is_image_based": extracted_data.get("is_image_based", False),
                "ocr_used": extracted_data.get("ocr_used", False),
                "processing_time": 0,
                "structured_data": extracted_data.get("structured_data", {}),
                "format": extracted_data.get("detected_format", "unknown"),
                "output_format": output_format
            })
        except Exception as e:
            logger.error(f"í•™ìŠµ ë°ì´í„° ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")

        logger.info(f"[{job_id}] ë²”ìš© ë³€í™˜ ì™„ë£Œ: {output_filename}")

        return JSONResponse({
            "success": True,
            "job_id": job_id,
            "message": "ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "result": {
                "url": f"/outputs/{output_filename}",
                "filename": output_filename,
                "original_filename": original_filename,
                "detected_format": extracted_data.get("detected_format", "unknown"),
                "parser_used": extracted_data.get("parser_used", "Unknown"),
                "content_type": content_type,
                "output_format": output_format,
                "title": result_title,
                "page_count": extracted_data.get("page_count", 0),
                "created_at": datetime.now().isoformat()
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[{job_id}] ë²”ìš© ë³€í™˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë³€í™˜ ì‹¤íŒ¨: {str(e)}")


# ============================================
# í…œí”Œë¦¿ ê´€ë¦¬ API
# ============================================

@app.get("/api/templates")
async def list_templates():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì¶œë ¥ í…œí”Œë¦¿ ëª©ë¡"""
    try:
        templates = template_engine.list_templates()
        return JSONResponse({
            "success": True,
            "templates": templates,
            "count": len(templates)
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/templates/custom")
async def create_custom_template(
    template_id: str = Form(...),
    name: str = Form(...),
    description: str = Form(...),
    template_content: str = Form(...)
):
    """ì‚¬ìš©ì ì •ì˜ í…œí”Œë¦¿ ìƒì„±"""
    try:
        success = template_engine.create_custom_template(
            template_id, name, description, template_content
        )

        if success:
            return JSONResponse({
                "success": True,
                "message": "ì»¤ìŠ¤í…€ í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
                "template_id": template_id
            })
        else:
            raise HTTPException(status_code=400, detail="í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ë‹¤êµ­ì–´ ì§€ì› API
# ============================================

@app.get("/api/languages")
async def get_supported_languages():
    """ì§€ì›í•˜ëŠ” ëª¨ë“  ì–¸ì–´ ëª©ë¡"""
    try:
        languages = localization_manager.get_supported_languages()
        return JSONResponse({
            "success": True,
            "languages": languages,
            "count": len(languages)
        })
    except Exception as e:
        logger.error(f"ì–¸ì–´ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/languages/detect")
async def detect_language(text: str = Form(...)):
    """í…ìŠ¤íŠ¸ì—ì„œ ì–¸ì–´ ìë™ ê°ì§€"""
    try:
        detected = localization_manager.detect_language(text)
        return JSONResponse({
            "success": True,
            "detected_language": detected
        })
    except Exception as e:
        logger.error(f"ì–¸ì–´ ê°ì§€ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• API
# ============================================

@app.post("/api/convert/custom")
async def custom_convert(
    file: UploadFile = File(...),
    content_type: str = Form("general"),
    output_format: str = Form("mobile_html"),
    title: Optional[str] = Form(None),
    language: str = Form("ko"),
    color_scheme: Optional[str] = Form(None),
    font_family: Optional[str] = Form(None),
    include_images: bool = Form(True),
    max_image_width: int = Form(800),
    custom_css: Optional[str] = Form(None),
    custom_header: Optional[str] = Form(None),
    custom_footer: Optional[str] = Form(None)
):
    """
    ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë³€í™˜ API

    Parameters:
    - file: ë³€í™˜í•  íŒŒì¼
    - content_type: ì½˜í…ì¸  íƒ€ì…
    - output_format: ì¶œë ¥ í˜•ì‹
    - title: ë¬¸ì„œ ì œëª©
    - language: ì–¸ì–´ ì½”ë“œ
    - color_scheme: ìƒ‰ìƒ í…Œë§ˆ (ì˜ˆ: "blue", "green", "#FF5733")
    - font_family: í°íŠ¸ (ì˜ˆ: "Malgun Gothic", "Arial")
    - include_images: ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€
    - max_image_width: ìµœëŒ€ ì´ë¯¸ì§€ ë„ˆë¹„
    - custom_css: ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼
    - custom_header: ì»¤ìŠ¤í…€ í—¤ë” HTML
    - custom_footer: ì»¤ìŠ¤í…€ í‘¸í„° HTML
    """
    job_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    try:
        # íŒŒì¼ ì €ì¥
        content = await file.read()
        original_filename = file.filename
        file_extension = Path(original_filename).suffix
        safe_filename = f"{job_id}_{timestamp}{file_extension}"
        upload_path = UPLOAD_DIR / safe_filename

        with open(upload_path, "wb") as f:
            f.write(content)

        logger.info(f"[{job_id}] ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë³€í™˜ ì‹œì‘: {original_filename}")

        # ì»¤ìŠ¤í…€ ì˜µì…˜ êµ¬ì„±
        custom_options = {
            'content_type': content_type,
            'output_format': output_format,
            'language': language,
            'color_scheme': color_scheme,
            'font_family': font_family,
            'include_images': include_images,
            'max_image_width': max_image_width,
        }

        # ë²”ìš© íŒŒì„œë¡œ ë¬¸ì„œ íŒŒì‹±
        extracted_data = universal_parser.parse_document(str(upload_path), custom_options)

        if 'error' in extracted_data:
            raise HTTPException(status_code=400, detail=extracted_data['error'])

        # ì¶œë ¥ ìƒì„±
        result_title = title or Path(original_filename).stem
        output_filename = f"{job_id}_{timestamp}.html"
        output_path = OUTPUT_DIR / output_filename

        # í…œí”Œë¦¿ ë°ì´í„° ì¤€ë¹„
        template_data = {
            'title': result_title,
            'language': language,
            'content': extracted_data.get('pages', []),
            'data': extracted_data
        }

        # ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ ì ìš©
        custom_styles = []
        if custom_css:
            custom_styles.append(custom_css)

        if color_scheme:
            custom_styles.append(f"""
                :root {{
                    --primary-color: {color_scheme};
                }}
            """)

        if font_family:
            custom_styles.append(f"""
                body {{
                    font-family: {font_family}, sans-serif;
                }}
            """)

        if custom_styles:
            template_data['custom_css'] = '\n'.join(custom_styles)

        if custom_header:
            template_data['custom_header'] = custom_header

        if custom_footer:
            template_data['custom_footer'] = custom_footer

        # í…œí”Œë¦¿ ë Œë”ë§
        rendered_output = template_engine.render(output_format, template_data)

        if not rendered_output:
            raise HTTPException(status_code=400, detail=f"í…œí”Œë¦¿ ë Œë”ë§ ì‹¤íŒ¨: {output_format}")

        # íŒŒì¼ ì €ì¥
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(rendered_output)

        logger.info(f"[{job_id}] ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë³€í™˜ ì™„ë£Œ: {output_filename}")

        # í•™ìŠµ ì‹œìŠ¤í…œì— ê¸°ë¡
        learning_system.log_conversion(job_id, {
            "filename": original_filename,
            "content_type": content_type,
            "page_count": extracted_data.get("page_count", 0),
            "is_image_based": extracted_data.get("is_image_based", False),
            "ocr_used": extracted_data.get("ocr_used", False),
            "structured_data": extracted_data.get("structured_data", {}),
        })

        return JSONResponse({
            "success": True,
            "job_id": job_id,
            "message": "ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "result": {
                "url": f"/outputs/{output_filename}",
                "filename": output_filename,
                "original_filename": original_filename,
                "title": result_title,
                "customizations": {
                    "color_scheme": color_scheme,
                    "font_family": font_family,
                    "include_images": include_images,
                    "has_custom_css": bool(custom_css),
                    "has_custom_header": bool(custom_header),
                    "has_custom_footer": bool(custom_footer)
                },
                "created_at": datetime.now().isoformat()
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[{job_id}] ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë³€í™˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë³€í™˜ ì‹¤íŒ¨: {str(e)}")


# ============================================
# íŒŒì¼ ê´€ë¦¬ API
# ============================================

@app.post("/api/cleanup")
async def cleanup_files(
    cleanup_uploads: bool = True,
    cleanup_outputs: bool = False,
    max_age_hours: int = 24
):
    """
    ì„ì‹œ íŒŒì¼ ìˆ˜ë™ ì •ë¦¬ API

    Parameters:
    - cleanup_uploads: uploads í´ë” ì •ë¦¬ (ê¸°ë³¸ê°’: True)
    - cleanup_outputs: outputs í´ë” ì •ë¦¬ (ê¸°ë³¸ê°’: False)
    - max_age_hours: ì‚­ì œí•  íŒŒì¼ì˜ ìµœì†Œ ë³´ê´€ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ê°’: 24ì‹œê°„)
    """
    try:
        deleted_count = 0

        if cleanup_uploads:
            deleted_files = cleanup_temp_files(
                job_id=None,
                keep_outputs=True,
                cleanup_old_files=True,
                max_age_hours=max_age_hours
            )
            deleted_count += len(deleted_files)

        if cleanup_outputs:
            deleted_files = cleanup_temp_files(
                job_id=None,
                keep_outputs=False,
                cleanup_old_files=True,
                max_age_hours=max_age_hours
            )
            deleted_count += len(deleted_files)

        return JSONResponse({
            "success": True,
            "message": f"{deleted_count}ê°œì˜ ì˜¤ë˜ëœ íŒŒì¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤",
            "deleted_count": deleted_count,
            "max_age_hours": max_age_hours
        })

    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/cleanup/all")
async def cleanup_all_files(confirm: bool = False):
    """
    ëª¨ë“  ì„ì‹œ íŒŒì¼ ê°•ì œ ì‚­ì œ API (ì£¼ì˜: outputs í´ë” í¬í•¨)

    Parameters:
    - confirm: ì‚­ì œ í™•ì¸ (Trueì—¬ì•¼ ì‹¤í–‰ë¨)
    """
    if not confirm:
        return JSONResponse({
            "success": False,
            "message": "ì‚­ì œë¥¼ í™•ì¸í•˜ë ¤ë©´ confirm=trueë¥¼ ì „ë‹¬í•˜ì„¸ìš”",
            "warning": "ì´ ì‘ì—…ì€ ëª¨ë“  uploads ë° outputs íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤"
        }, status_code=400)

    try:
        # uploads í´ë” ì „ì²´ ì‚­ì œ
        uploads_deleted = cleanup_temp_files(job_id=None, keep_outputs=True, cleanup_old_files=False)

        # outputs í´ë” ì „ì²´ ì‚­ì œ
        outputs_deleted = cleanup_temp_files(job_id=None, keep_outputs=False, cleanup_old_files=False)

        total_deleted = len(uploads_deleted) + len(outputs_deleted)

        return JSONResponse({
            "success": True,
            "message": f"ì´ {total_deleted}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ",
            "uploads_deleted": len(uploads_deleted),
            "outputs_deleted": len(outputs_deleted)
        })

    except Exception as e:
        logger.error(f"ì „ì²´ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/storage/status")
async def storage_status():
    """ì €ì¥ì†Œ ìƒíƒœ í™•ì¸ API"""
    try:
        import os

        # uploads í´ë” í†µê³„
        uploads_files = list(UPLOAD_DIR.glob("*"))
        uploads_count = len([f for f in uploads_files if f.is_file()])
        uploads_size = sum(f.stat().st_size for f in uploads_files if f.is_file())

        # outputs í´ë” í†µê³„
        outputs_files = list(OUTPUT_DIR.glob("*.html"))
        outputs_count = len(outputs_files)
        outputs_size = sum(f.stat().st_size for f in outputs_files)

        return JSONResponse({
            "success": True,
            "storage": {
                "uploads": {
                    "file_count": uploads_count,
                    "total_size_bytes": uploads_size,
                    "total_size_mb": round(uploads_size / 1024 / 1024, 2)
                },
                "outputs": {
                    "file_count": outputs_count,
                    "total_size_bytes": outputs_size,
                    "total_size_mb": round(outputs_size / 1024 / 1024, 2)
                },
                "total": {
                    "file_count": uploads_count + outputs_count,
                    "total_size_bytes": uploads_size + outputs_size,
                    "total_size_mb": round((uploads_size + outputs_size) / 1024 / 1024, 2)
                }
            }
        })

    except Exception as e:
        logger.error(f"ì €ì¥ì†Œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# íŒŒì¼ ë¸Œë¼ìš°ì € API
# ============================================

def fix_korean_filename(name: str) -> str:
    """
    Windowsì—ì„œ í•œê¸€ íŒŒì¼ëª…ì˜ surrogate escape ë¬¸ì œ í•´ê²°
    Python pathlibì´ ë°˜í™˜í•˜ëŠ” surrogate-escaped ë¬¸ìì—´ì„ ì •ìƒ í•œê¸€ë¡œ ë³€í™˜
    """
    try:
        # ì´ë¯¸ ì •ìƒì ì¸ ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        name.encode('utf-8')
        return name
    except UnicodeEncodeError:
        # surrogate escapeê°€ ìˆëŠ” ê²½ìš°
        try:
            # surrogateescapeë¡œ ë°”ì´íŠ¸ë¡œ ë³€í™˜ í›„ cp949ë¡œ ë””ì½”ë“œ ì‹œë„
            raw_bytes = name.encode('utf-8', errors='surrogateescape')
            return raw_bytes.decode('cp949', errors='replace')
        except Exception:
            try:
                # euc-kr ì‹œë„
                raw_bytes = name.encode('utf-8', errors='surrogateescape')
                return raw_bytes.decode('euc-kr', errors='replace')
            except Exception:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: replace ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì‚¬ìš©
                return name.encode('utf-8', errors='replace').decode('utf-8')

@app.get("/api/files/{folder:path}")
async def list_folder_files(folder: str, subpath: str = ""):
    """
    í´ë”ë³„ íŒŒì¼ ëª©ë¡ ë°˜í™˜ (íŒŒì¼ ë¸Œë¼ìš°ì €ìš©)
    í•˜ìœ„ í´ë” íƒìƒ‰ ì§€ì›

    - folder: outputs, uploads, static, templates, root ë˜ëŠ” outputs/í•˜ìœ„í´ë”
    - subpath: í•˜ìœ„ ê²½ë¡œ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°)
    """
    try:
        # ê¸°ë³¸ í´ë” ë§¤í•‘
        base_folders = {
            'outputs': OUTPUT_DIR,
            'uploads': UPLOAD_DIR,
            'static': STATIC_DIR,
            'templates': TEMPLATES_DIR,
            'root': BASE_DIR
        }

        # folderê°€ "outputs/êµ­ë¯¼-ë‚˜ê²½ì›" í˜•íƒœì¸ ê²½ìš° íŒŒì‹±
        parts = folder.split('/')
        base_folder = parts[0]
        sub_path = '/'.join(parts[1:]) if len(parts) > 1 else ""

        if base_folder not in base_folders:
            raise HTTPException(status_code=400, detail=f"í—ˆìš©ë˜ì§€ ì•Šì€ í´ë”: {base_folder}")

        folder_path = base_folders[base_folder]

        # í•˜ìœ„ ê²½ë¡œê°€ ìˆìœ¼ë©´ ì ìš©
        if sub_path:
            folder_path = folder_path / sub_path

        # ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
        try:
            folder_path = folder_path.resolve()
            base_path = base_folders[base_folder].resolve()
            if not str(folder_path).startswith(str(base_path)):
                raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")
        except Exception:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        if not folder_path.exists():
            return JSONResponse({
                "success": True,
                "files": [],
                "folders": [],
                "count": 0,
                "folder": folder,
                "current_path": sub_path,
                "total_size": 0
            })

        files = []
        folders = []
        total_size = 0

        for item_path in folder_path.iterdir():
            try:
                # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
                fixed_name = fix_korean_filename(item_path.name)

                if item_path.is_dir():
                    # í•˜ìœ„ í´ë”
                    folder_files = list(item_path.glob('*'))
                    folders.append({
                        "name": fixed_name,
                        "type": "folder",
                        "file_count": len([f for f in folder_files if f.is_file()]),
                        "path": f"{base_folder}/{sub_path}/{fixed_name}".replace('//', '/')
                    })
                elif item_path.is_file():
                    # íŒŒì¼
                    stat = item_path.stat()
                    total_size += stat.st_size

                    # URL ê²½ë¡œ êµ¬ì„±
                    if sub_path:
                        url = f"/{base_folder}/{sub_path}/{fixed_name}"
                    else:
                        url = f"/{base_folder}/{fixed_name}"

                    files.append({
                        "name": fixed_name,
                        "type": "file",
                        "size": stat.st_size,
                        "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "url": url,
                        "folder_path": sub_path
                    })
            except Exception as e:
                logger.warning(f"í•­ëª© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {item_path} - {str(e)}")

        # í´ë”ëŠ” ì´ë¦„ìˆœ, íŒŒì¼ì€ ìµœì‹ ìˆœ ì •ë ¬
        folders.sort(key=lambda x: x["name"])
        files.sort(key=lambda x: x["modified"], reverse=True)

        import json
        return JSONResponse(
            content={
                "success": True,
                "files": files,
                "folders": folders,
                "count": len(files),
                "folder_count": len(folders),
                "folder": base_folder,
                "current_path": sub_path,
                "total_size": total_size
            },
            media_type="application/json; charset=utf-8"
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í´ë” íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/serve/{file_path:path}")
async def serve_file(file_path: str):
    """
    í•œê¸€ ê²½ë¡œë¥¼ ì§€ì›í•˜ëŠ” íŒŒì¼ ì„œë¹™ API
    StaticFilesì˜ í•œê¸€ ì¸ì½”ë”© ë¬¸ì œë¥¼ ìš°íšŒ

    ì‚¬ìš©ë²•: /api/serve/outputs/ë¯¼ì£¼-ë¥˜ì‚¼ì˜/ë¥˜ì‚¼ì˜_with_images.html
    """
    try:
        from urllib.parse import unquote

        # URL ë””ì½”ë”© (í•œê¸€ ì²˜ë¦¬)
        decoded_path = unquote(file_path)

        # outputs, uploads, static í´ë”ë§Œ í—ˆìš©
        allowed_prefixes = {
            'outputs': OUTPUT_DIR,
            'uploads': UPLOAD_DIR,
            'static': STATIC_DIR,
        }

        # ê²½ë¡œ íŒŒì‹±
        parts = decoded_path.split('/')
        if len(parts) < 2:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        base_folder = parts[0]
        if base_folder not in allowed_prefixes:
            raise HTTPException(status_code=400, detail=f"í—ˆìš©ë˜ì§€ ì•Šì€ í´ë”: {base_folder}")

        # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        relative_path = '/'.join(parts[1:])
        full_path = allowed_prefixes[base_folder] / relative_path

        # ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
        full_path = full_path.resolve()
        base_path = allowed_prefixes[base_folder].resolve()
        if not str(full_path).startswith(str(base_path)):
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")

        if not full_path.exists():
            raise HTTPException(status_code=404, detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {decoded_path}")

        if not full_path.is_file():
            raise HTTPException(status_code=400, detail="ë””ë ‰í† ë¦¬ëŠ” ì„œë¹™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # MIME íƒ€ì… ê²°ì •
        import mimetypes
        mime_type, _ = mimetypes.guess_type(str(full_path))
        if mime_type is None:
            mime_type = "application/octet-stream"

        return FileResponse(
            path=str(full_path),
            media_type=mime_type,
            filename=full_path.name
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì„œë¹™ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì„œë¹™ ì‹¤íŒ¨: {str(e)}")


@app.delete("/api/files/{folder}/{filename}")
async def delete_folder_file(folder: str, filename: str):
    """
    í´ë”ì—ì„œ íŒŒì¼ ì‚­ì œ
    """
    try:
        # í—ˆìš©ëœ í´ë”ë§Œ ì ‘ê·¼ ê°€ëŠ¥
        allowed_folders = {
            'outputs': OUTPUT_DIR,
            'uploads': UPLOAD_DIR,
            'static': STATIC_DIR,
            'templates': TEMPLATES_DIR,
            'root': BASE_DIR  # ë£¨íŠ¸ í´ë” (Python íŒŒì¼ìš©)
        }

        if folder not in allowed_folders:
            raise HTTPException(status_code=400, detail=f"í—ˆìš©ë˜ì§€ ì•Šì€ í´ë”: {folder}")

        # ë³´ì•ˆ: íŒŒì¼ëª… ê²€ì¦ (ê²½ë¡œ ì¡°ì‘ ë°©ì§€)
        if ".." in filename or "/" in filename or "\\" in filename:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤")

        folder_path = allowed_folders[folder]
        file_path = folder_path / filename

        if not file_path.exists():
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        if not file_path.is_file():
            raise HTTPException(status_code=400, detail="íŒŒì¼ë§Œ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

        file_path.unlink()
        logger.info(f"íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {folder}/{filename}")

        return JSONResponse({
            "success": True,
            "message": "íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤",
            "folder": folder,
            "filename": filename
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/editor/files")
async def list_html_files():
    """
    í¸ì§‘ ê°€ëŠ¥í•œ HTML íŒŒì¼ ëª©ë¡ ë°˜í™˜
    """
    try:
        files = []
        for file_path in OUTPUT_DIR.glob("*.html"):
            if file_path.is_file():
                stat = file_path.stat()
                files.append({
                    "name": file_path.name,
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "url": f"/outputs/{file_path.name}"
                })

        # ìµœì‹  íŒŒì¼ ìš°ì„  ì •ë ¬
        files.sort(key=lambda x: x["modified"], reverse=True)

        return JSONResponse({
            "success": True,
            "files": files,
            "count": len(files)
        })

    except Exception as e:
        logger.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")




@app.post("/api/convert-pdf")
async def convert_pdf_for_editor(
    file: UploadFile = File(...),
    output_name: Optional[str] = Form(default=None)
):
    """
    ì—ë””í„°ìš© ê°„ì†Œí™”ëœ PDF ë³€í™˜ API
    
    - file: PDF íŒŒì¼
    - output_name: ì¶œë ¥ íŒŒì¼ëª… (ì„ íƒì‚¬í•­)
    
    Returns:
    - success: ì„±ê³µ ì—¬ë¶€
    - filename: ìƒì„±ëœ HTML íŒŒì¼ëª…
    - url: íŒŒì¼ URL
    """
    
    # íŒŒì¼ ê²€ì¦
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # íŒŒì¼ í¬ê¸° ì œí•œ (50MB)
    MAX_FILE_SIZE = 50 * 1024 * 1024
    pdf_content = await file.read()
    if len(pdf_content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ëŠ” 50MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ê³ ìœ  ID ìƒì„±
    job_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # íŒŒì¼ ì €ì¥
    original_filename = file.filename
    safe_filename = f"{job_id}_{timestamp}.pdf"
    upload_path = UPLOAD_DIR / safe_filename
    
    try:
        with open(upload_path, "wb") as f:
            f.write(pdf_content)
        
        logger.info(f"[{job_id}] ì—ë””í„° PDF ë³€í™˜ ì‹œì‘: {original_filename}")
        
        # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ
        try:
            extracted_data = pdf_converter.extract_from_pdf(
                str(upload_path),
                content_type="general",
                exclude_pages=[]
            )
        except Exception as e:
            logger.error(f"[{job_id}] PDF ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        if not extracted_data:
            logger.error(f"[{job_id}] PDF ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŒ")
            raise HTTPException(status_code=500, detail="PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
        
        logger.info(f"[{job_id}] PDF ì¶”ì¶œ ì™„ë£Œ: {extracted_data.get('page_count', 0)}í˜ì´ì§€")
        
        # 2. HTML ìƒì„±
        result_title = output_name if output_name else Path(original_filename).stem
        
        # ì¶œë ¥ íŒŒì¼ëª… ìƒì„± - output_nameì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìë™ ìƒì„±
        if output_name:
            # ì‚¬ìš©ì ì§€ì • íŒŒì¼ëª… (í™•ì¥ì ì²˜ë¦¬)
            if not output_name.lower().endswith('.html'):
                output_name += '.html'
            output_filename = output_name
        else:
            # ì›ë³¸ PDF íŒŒì¼ëª… ê¸°ë°˜ ìë™ ìƒì„±
            safe_pdf_name = Path(original_filename).stem
            safe_pdf_name = "".join(c for c in safe_pdf_name if c.isalnum() or c in ('_', '-', ' ', 'ê°€', 'ë‚˜', 'ë‹¤') or ord(c) > 127).strip()
            if not safe_pdf_name:
                safe_pdf_name = "document"
            output_filename = f"{safe_pdf_name}_{timestamp}.html"
        
        output_path = OUTPUT_DIR / output_filename
        
        try:
            html_content = html_generator.generate_html(
                extracted_data=extracted_data,
                title=result_title,
                content_type="general",
                job_id=job_id
            )
        except Exception as e:
            logger.error(f"[{job_id}] HTML ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"HTML ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # HTML íŒŒì¼ ì €ì¥
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(html_content)
        
        logger.info(f"[{job_id}] HTML ë³€í™˜ ì™„ë£Œ: {output_filename}")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files(job_id=job_id, keep_outputs=True)
        
        result_url = f"/outputs/{output_filename}"
        
        return JSONResponse({
            "success": True,
            "filename": output_filename,
            "url": result_url,
            "title": result_title,
            "page_count": extracted_data.get('page_count', 0)
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[{job_id}] PDF ë³€í™˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files(job_id=job_id, keep_outputs=False)
        raise HTTPException(status_code=500, detail=f"PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.post("/api/upload-image")
async def upload_image(file: UploadFile = File(...)):
    """
    ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ API (ì—ë””í„°ìš©)

    - file: ì—…ë¡œë“œí•  ì´ë¯¸ì§€ íŒŒì¼ (jpg, jpeg, png, gif, webp, svg)

    Returns:
    - success: ì„±ê³µ ì—¬ë¶€
    - url: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ URL
    - filename: ì €ì¥ëœ íŒŒì¼ëª…
    """
    try:
        # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
        allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.bmp', '.ico'}

        original_filename = file.filename
        file_extension = Path(original_filename).suffix.lower()

        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
            )

        # íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
        MAX_IMAGE_SIZE = 10 * 1024 * 1024
        content = await file.read()

        if len(content) > MAX_IMAGE_SIZE:
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ í¬ê¸°ëŠ” 10MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ê³ ìœ  íŒŒì¼ëª… ìƒì„± (ì›ë³¸ ì´ë¦„ ìœ ì§€ + íƒ€ì„ìŠ¤íƒ¬í”„)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = Path(original_filename).stem
        # íŒŒì¼ëª…ì—ì„œ ì•ˆì „í•˜ì§€ ì•Šì€ ë¬¸ì ì œê±°
        safe_name = "".join(c for c in safe_name if c.isalnum() or c in ('_', '-', ' ')).strip()
        if not safe_name:
            safe_name = "image"

        new_filename = f"{safe_name}_{timestamp}{file_extension}"

        # static/images ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        images_dir = STATIC_DIR / "images"
        images_dir.mkdir(exist_ok=True)

        # íŒŒì¼ ì €ì¥
        file_path = images_dir / new_filename

        with open(file_path, "wb") as f:
            f.write(content)

        logger.info(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ: {new_filename} ({len(content)} bytes)")

        return JSONResponse({
            "success": True,
            "message": "ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
            "url": f"/static/images/{new_filename}",
            "filename": new_filename,
            "original_filename": original_filename,
            "size": len(content)
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/images")
async def list_images():
    """
    ì„œë²„ì— ì €ì¥ëœ ì´ë¯¸ì§€ ëª©ë¡ ë°˜í™˜ (ì—ë””í„° ê°¤ëŸ¬ë¦¬ìš©)
    """
    try:
        images_dir = STATIC_DIR / "images"

        if not images_dir.exists():
            return JSONResponse({
                "success": True,
                "images": [],
                "count": 0
            })

        images = []
        allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.bmp', '.ico'}

        for file_path in images_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in allowed_extensions:
                try:
                    stat = file_path.stat()
                    images.append({
                        "name": file_path.name,
                        "url": f"/static/images/{file_path.name}",
                        "size": stat.st_size,
                        "modified": datetime.fromtimestamp(stat.st_mtime).isoformat()
                    })
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {file_path.name} - {str(e)}")

        # ìµœì‹  íŒŒì¼ ìš°ì„  ì •ë ¬
        images.sort(key=lambda x: x["modified"], reverse=True)

        return JSONResponse({
            "success": True,
            "images": images,
            "count": len(images)
        })

    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


# ============================================
# í´ë” ZIP ë‹¤ìš´ë¡œë“œ API
# ============================================

@app.get("/api/download/folder/{folder_path:path}")
async def download_folder_as_zip(folder_path: str):
    """
    outputs í´ë” ë‚´ íŠ¹ì • í´ë”ë¥¼ ZIP íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ

    ì˜ˆ: /api/download/folder/Minjoo/ë¥˜ì‚¼ì˜ -> Minjoo/ë¥˜ì‚¼ì˜ í´ë”ë¥¼ ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
    """
    try:
        # í´ë” ê²½ë¡œ ê²€ì¦
        folder_path = unquote(folder_path)
        target_path = OUTPUT_DIR / folder_path

        # ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
        try:
            target_path = target_path.resolve()
            if not str(target_path).startswith(str(OUTPUT_DIR.resolve())):
                raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")
        except Exception:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        if not target_path.exists():
            raise HTTPException(status_code=404, detail=f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")

        if not target_path.is_dir():
            raise HTTPException(status_code=400, detail="í´ë”ê°€ ì•„ë‹™ë‹ˆë‹¤")

        # ZIP íŒŒì¼ ìƒì„± (ë©”ëª¨ë¦¬ì—)
        zip_buffer = io.BytesIO()

        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì¶”ê°€
            for file_path in target_path.rglob('*'):
                if file_path.is_file():
                    # ZIP ë‚´ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                    arcname = file_path.relative_to(target_path.parent)
                    zip_file.write(file_path, arcname)

        zip_buffer.seek(0)

        # íŒŒì¼ëª… ì„¤ì • (ë§ˆì§€ë§‰ í´ë”ëª… ì‚¬ìš©)
        zip_filename = f"{target_path.name}.zip"

        # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”©
        encoded_filename = quote(zip_filename)

        return StreamingResponse(
            zip_buffer,
            media_type="application/zip",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{encoded_filename}"
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í´ë” ZIP ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ZIP ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


# ============================================
# í•™ìŠµ ì‹œìŠ¤í…œ API
# ============================================

@app.post("/api/learning/classify")
async def classify_text(request: Request):
    """
    í…ìŠ¤íŠ¸ ê°ì²´ ë¶„ë¥˜ API

    í…ìŠ¤íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì •ë³´ë¥¼ ë°›ì•„ PDF ê°ì²´ ìœ í˜•ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    try:
        from learning_data import ObjectClassifier, TextStyle, FontStyle, BoundingBox

        data = await request.json()
        text = data.get("text", "")
        style_data = data.get("style", {})
        bbox_data = data.get("bbox", {})

        classifier = ObjectClassifier()

        # ìŠ¤íƒ€ì¼ ê°ì²´ ìƒì„±
        style = None
        if style_data:
            style = TextStyle(
                font_name=style_data.get("font_name", "Unknown"),
                font_size=float(style_data.get("font_size", 12.0)),
                font_style=FontStyle(style_data.get("font_style", "regular")),
                color=style_data.get("color", "#000000")
            )

        # ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
        bbox = None
        if bbox_data:
            bbox = BoundingBox(
                x=float(bbox_data.get("x", 0)),
                y=float(bbox_data.get("y", 0)),
                width=float(bbox_data.get("width", 0)),
                height=float(bbox_data.get("height", 0)),
                page=int(bbox_data.get("page", 1))
            )

        # ë¶„ë¥˜ ì‹¤í–‰
        obj_type, confidence = classifier.classify(text, style, bbox)

        return JSONResponse({
            "success": True,
            "text": text[:100],
            "classification": {
                "type": obj_type.value,
                "type_name": obj_type.name,
                "confidence": round(confidence, 4)
            },
            "html_mapping": classifier._get_html_mapping(obj_type)
        })

    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/learning/validate")
async def validate_text(request: Request):
    """
    í…ìŠ¤íŠ¸ ê²€ì¦ API

    ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ì˜¤ë¥˜ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        from learning_data import TextValidator

        data = await request.json()
        original = data.get("original", "")
        converted = data.get("converted", "")

        if not original or not converted:
            raise HTTPException(status_code=400, detail="originalê³¼ converted í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        validator = TextValidator()
        report = validator.validate(original, converted)

        return JSONResponse({
            "success": True,
            "validation": report.to_dict()
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/learning/validate-document")
async def validate_document(request: Request):
    """
    ë¬¸ì„œ ì „ì²´ ê²€ì¦ API

    ì—¬ëŸ¬ í˜ì´ì§€ì˜ ì›ë³¸ê³¼ ë³€í™˜ í…ìŠ¤íŠ¸ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    """
    try:
        from learning_data import BatchValidator

        data = await request.json()
        original_pages = data.get("original_pages", [])
        converted_pages = data.get("converted_pages", [])

        if not original_pages or not converted_pages:
            raise HTTPException(status_code=400, detail="original_pagesì™€ converted_pagesê°€ í•„ìš”í•©ë‹ˆë‹¤")

        validator = BatchValidator()
        result = validator.validate_document(original_pages, converted_pages)

        # ì¤‘ìš” ì˜¤ë¥˜ë§Œ ë³„ë„ ì¶”ì¶œ
        critical_errors = validator.get_critical_errors(min_confidence=0.8)

        return JSONResponse({
            "success": True,
            "document_validation": result,
            "critical_errors": critical_errors[:20]  # ìƒìœ„ 20ê°œë§Œ
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ê²€ì¦ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/learning/object-types")
async def get_object_types():
    """
    ì§€ì›í•˜ëŠ” ê°ì²´ ìœ í˜• ëª©ë¡ ë°˜í™˜
    """
    try:
        from learning_data import ObjectType, ELECTION_MAPPINGS

        types = []
        for obj_type in ObjectType:
            mapping = ELECTION_MAPPINGS.get(obj_type)
            types.append({
                "code": obj_type.value,
                "name": obj_type.name,
                "has_template": mapping is not None,
                "css_class": mapping.css_class if mapping else None
            })

        return JSONResponse({
            "success": True,
            "object_types": types,
            "total": len(types)
        })

    except Exception as e:
        logger.error(f"ê°ì²´ ìœ í˜• ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/learning/diff")
async def get_text_diff(request: Request):
    """
    ì›ë³¸ê³¼ ë³€í™˜ í…ìŠ¤íŠ¸ì˜ ì°¨ì´ë¥¼ HTMLë¡œ ë°˜í™˜
    """
    try:
        from learning_data import TextValidator

        data = await request.json()
        original = data.get("original", "")
        converted = data.get("converted", "")

        validator = TextValidator()
        diff_html = validator.get_diff_html(original, converted)

        return JSONResponse({
            "success": True,
            "diff_html": diff_html
        })

    except Exception as e:
        logger.error(f"ì°¨ì´ ë¹„êµ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/editor/save")
async def save_html_file(request: Request):
    """
    HTML ì—ë””í„°ì—ì„œ íŒŒì¼ ì €ì¥ (í•˜ìœ„ í´ë” ì§€ì›) + ìë™ í•™ìŠµ

    - filename: ì €ì¥í•  íŒŒì¼ëª… ë˜ëŠ” ê²½ë¡œ (ì˜ˆ: êµ­ë¯¼-ë‚˜ê²½ì›/NA_xxx.html, outputs/êµ­ë¯¼-ë‚˜ê²½ì›/NA_xxx.html)
    - content: HTML ë‚´ìš©

    ì €ì¥ ì‹œ ì›ë³¸ê³¼ ë¹„êµí•˜ì—¬ ìë™ìœ¼ë¡œ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    """
    try:
        # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ëª…ì‹œì ìœ¼ë¡œ body ì½ê¸°
        body = await request.body()
        text = body.decode('utf-8')
        import json
        data = json.loads(text)
        filename = data.get("filename")
        content = data.get("content")

        if not filename or not content:
            raise HTTPException(status_code=400, detail="filenameê³¼ contentê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # ë³´ì•ˆ: ìƒìœ„ ë””ë ‰í† ë¦¬ ì ‘ê·¼ ë°©ì§€
        if ".." in filename:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤")

        # íŒŒì¼ ê²½ë¡œ ì •ê·œí™”
        # outputs/í•˜ìœ„í´ë”/íŒŒì¼ëª… ë˜ëŠ” í•˜ìœ„í´ë”/íŒŒì¼ëª… í˜•íƒœ ì§€ì›
        filename = filename.replace("\\", "/")  # ìœˆë„ìš° ê²½ë¡œ ì •ê·œí™”

        if filename.startswith("outputs/"):
            filename = filename[8:]  # "outputs/" ì œê±°

        if not filename.endswith(".html"):
            raise HTTPException(status_code=400, detail="HTML íŒŒì¼ë§Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

        # íŒŒì¼ ì €ì¥ ê²½ë¡œ
        file_path = OUTPUT_DIR / filename

        # ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
        try:
            file_path = file_path.resolve()
            if not str(file_path).startswith(str(OUTPUT_DIR.resolve())):
                raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")
        except Exception:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        # í•˜ìœ„ í´ë”ê°€ ìˆìœ¼ë©´ ìƒì„±
        file_path.parent.mkdir(parents=True, exist_ok=True)

        # ========================================
        # ìë™ í•™ìŠµ: ì›ë³¸ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ì  í•™ìŠµ
        # ========================================
        learning_result = None
        original_html = ""

        if file_path.exists() and active_learning_engine is not None:
            try:
                # ì›ë³¸ HTML ì½ê¸°
                with open(file_path, 'r', encoding='utf-8') as f:
                    original_html = f.read()

                # ë‚´ìš©ì´ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ í•™ìŠµ
                if original_html.strip() != content.strip():
                    # job_id ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)
                    import hashlib
                    job_id = hashlib.md5(filename.encode()).hexdigest()[:8]

                    # HTML diff ë¶„ì„ ë° íŒ¨í„´ í•™ìŠµ
                    diff = active_learning_engine.save_html_diff(
                        job_id=job_id,
                        original_html=original_html,
                        modified_html=content
                    )

                    # í›„ë³´ì ì •ë³´ ì¶”ì¶œ (í•™ìŠµ ë©”íƒ€ë°ì´í„°)
                    import re
                    candidate_match = re.search(r'<h1[^>]*class="[^"]*hero-name[^"]*"[^>]*>([^<]+)</h1>', content)
                    party_match = re.search(r'<span[^>]*class="[^"]*party-badge[^"]*"[^>]*>([^<]+)</span>', content)

                    learning_result = {
                        "changes_count": len(diff.changes),
                        "patterns_count": len(diff.extracted_patterns),
                        "candidate": candidate_match.group(1) if candidate_match else None,
                        "party": party_match.group(1) if party_match else None
                    }

                    logger.info(f"[ìë™í•™ìŠµ] {filename}: {len(diff.changes)}ê°œ ë³€ê²½, {len(diff.extracted_patterns)}ê°œ íŒ¨í„´ ì¶”ì¶œ")

            except Exception as e:
                logger.warning(f"ìë™ í•™ìŠµ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")

        # íŒŒì¼ ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

        logger.info(f"HTML íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename} ({len(content)} bytes)")

        response_data = {
            "success": True,
            "message": "íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            "filename": filename,
            "size": len(content)
        }

        # í•™ìŠµ ê²°ê³¼ í¬í•¨
        if learning_result:
            response_data["learning"] = learning_result
            response_data["message"] = f"íŒŒì¼ ì €ì¥ + {learning_result['changes_count']}ê°œ ë³€ê²½ì  í•™ìŠµë¨"

        return JSONResponse(response_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/editor/upload")
async def upload_file(
    file: UploadFile = File(...),
    folder: str = Form(default="outputs"),
    subfolder: str = Form(default="")
):
    """
    íŒŒì¼ ì—…ë¡œë“œ (HTML, Python, ì´ë¯¸ì§€)

    - ë¡œì»¬ì—ì„œ ì‘ì—…í•œ íŒŒì¼ì„ ì„œë²„ì— ì—…ë¡œë“œ
    - folder íŒŒë¼ë¯¸í„°ë¡œ ì €ì¥ ìœ„ì¹˜ ì„ íƒ ê°€ëŠ¥ (outputs, static, uploads)
    - subfolder íŒŒë¼ë¯¸í„°ë¡œ í•˜ìœ„ í´ë” ê²½ë¡œ ì§€ì • ê°€ëŠ¥ (ì˜ˆ: Minjoo/images)
    - í—ˆìš© íŒŒì¼: .html, .htm, .py, .png, .jpg, .jpeg, .gif, .svg, .webp
    """
    try:
        # í—ˆìš©ëœ í´ë”ë§Œ ì‚¬ìš© ê°€ëŠ¥
        allowed_folders = {
            "outputs": OUTPUT_DIR,
            "static": STATIC_DIR,
            "uploads": UPLOAD_DIR,
            "root": BASE_DIR  # ë£¨íŠ¸ í´ë” (Python íŒŒì¼ìš©)
        }

        if folder not in allowed_folders:
            raise HTTPException(status_code=400, detail=f"í—ˆìš©ë˜ì§€ ì•Šì€ í´ë”ì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {list(allowed_folders.keys())}")

        target_dir = allowed_folders[folder]

        # íŒŒì¼ í™•ì¥ì ê²€ì¦
        allowed_extensions = ['.html', '.htm', '.py', '.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp']
        file_ext = '.' + file.filename.split('.')[-1].lower() if '.' in file.filename else ''
        if file_ext not in allowed_extensions:
            raise HTTPException(status_code=400, detail=f"í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©: {', '.join(allowed_extensions)}")

        # ì´ë¯¸ì§€ íŒŒì¼ ì—¬ë¶€ í™•ì¸
        is_image = file_ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp']

        # ë³´ì•ˆ: íŒŒì¼ëª… ê²€ì¦ (ê²½ë¡œ ì¡°ì‘ ë°©ì§€)
        filename = file.filename
        if ".." in filename:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤")

        # subfolder ê²½ë¡œ ê²€ì¦ ë° ì²˜ë¦¬
        if subfolder:
            # ê²½ë¡œ êµ¬ë¶„ì ì •ê·œí™” ë° ë³´ì•ˆ ê²€ì‚¬
            subfolder = subfolder.replace("\\", "/").strip("/")
            if ".." in subfolder:
                raise HTTPException(status_code=400, detail="ì˜ëª»ëœ í•˜ìœ„ í´ë” ê²½ë¡œì…ë‹ˆë‹¤")
            # í•˜ìœ„ í´ë” ê²½ë¡œë¥¼ target_dirì— ì¶”ê°€
            target_dir = target_dir / subfolder

        # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        target_dir.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        content = await file.read()

        # íŒŒì¼ ì €ì¥ ê²½ë¡œ
        file_path = target_dir / filename

        if is_image:
            # ì´ë¯¸ì§€ íŒŒì¼ì€ ë°”ì´ë„ˆë¦¬ë¡œ ì €ì¥
            with open(file_path, 'wb') as f:
                f.write(content)
            file_size = len(content)
        else:
            # í…ìŠ¤íŠ¸ íŒŒì¼ì€ UTF-8ë¡œ ì €ì¥
            try:
                content_str = content.decode('utf-8')
            except UnicodeDecodeError:
                content_str = content.decode('cp949')  # í•œê¸€ Windows ì¸ì½”ë”©

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content_str)
            file_size = len(content_str)

        # ì „ì²´ ì €ì¥ ê²½ë¡œ ê³„ì‚°
        full_path = f"{folder}/{subfolder}/{filename}" if subfolder else f"{folder}/{filename}"
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {full_path} ({file_size} bytes)")

        return JSONResponse({
            "success": True,
            "message": f"íŒŒì¼ì´ {full_path}ì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
            "filename": filename,
            "folder": folder,
            "subfolder": subfolder,
            "size": file_size,
            "url": f"/{full_path}"
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


# ============================================
# ë²”ìš© í´ë” íƒìƒ‰ API (ìœˆë„ìš° íƒìƒ‰ê¸° ìŠ¤íƒ€ì¼)
# ============================================

@app.get("/api/browse")
async def browse_folder(path: str = ""):
    """
    ë²”ìš© í´ë” íƒìƒ‰ API - ìœˆë„ìš° íƒìƒ‰ê¸°ì²˜ëŸ¼ ì„ì˜ ê²½ë¡œ íƒìƒ‰

    - pathê°€ ë¹„ì–´ìˆìœ¼ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸(BASE_DIR)ì˜ ë‚´ìš© ë°˜í™˜
    - pathê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê²½ë¡œì˜ í´ë”/íŒŒì¼ ëª©ë¡ ë°˜í™˜
    - ë³´ì•ˆ: BASE_DIR í•˜ìœ„ë§Œ ì ‘ê·¼ ê°€ëŠ¥
    """
    try:
        # ê²½ë¡œ ì •ê·œí™”
        path = path.replace("\\", "/").strip("/")

        # ë³´ì•ˆ ê²€ì‚¬
        if ".." in path:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        # ì „ì²´ ê²½ë¡œ ê³„ì‚°
        if path:
            target_path = BASE_DIR / path
        else:
            target_path = BASE_DIR

        # ê²½ë¡œê°€ BASE_DIR í•˜ìœ„ì¸ì§€ í™•ì¸
        try:
            target_path.resolve().relative_to(BASE_DIR.resolve())
        except ValueError:
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")

        # ê²½ë¡œ ì¡´ì¬ í™•ì¸
        if not target_path.exists():
            raise HTTPException(status_code=404, detail=f"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")

        # íŒŒì¼ì¸ ê²½ìš°
        if target_path.is_file():
            stat = target_path.stat()
            return JSONResponse({
                "success": True,
                "type": "file",
                "path": path,
                "name": target_path.name,
                "size": stat.st_size,
                "modified": stat.st_mtime
            })

        # í´ë”ì¸ ê²½ìš° - ë‚´ìš© ëª©ë¡ ë°˜í™˜
        items = []
        folders = []
        files = []

        for item in target_path.iterdir():
            try:
                stat = item.stat()
                item_info = {
                    "name": item.name,
                    "path": f"{path}/{item.name}" if path else item.name,
                    "size": stat.st_size,
                    "modified": stat.st_mtime,
                    "is_dir": item.is_dir()
                }

                if item.is_dir():
                    # í´ë” ë‚´ í•­ëª© ìˆ˜ ê³„ì‚°
                    try:
                        item_info["children_count"] = len(list(item.iterdir()))
                    except:
                        item_info["children_count"] = 0
                    folders.append(item_info)
                else:
                    # íŒŒì¼ í™•ì¥ì
                    item_info["extension"] = item.suffix.lower()
                    files.append(item_info)
            except Exception as e:
                # ì ‘ê·¼ ê¶Œí•œ ì—†ëŠ” íŒŒì¼ ìŠ¤í‚µ
                continue

        # ì •ë ¬: í´ë” ë¨¼ì €, ì´ë¦„ìˆœ
        folders.sort(key=lambda x: x["name"].lower())
        files.sort(key=lambda x: x["name"].lower())
        items = folders + files

        # ìƒìœ„ ê²½ë¡œ ê³„ì‚°
        parent_path = "/".join(path.split("/")[:-1]) if path else None

        return JSONResponse({
            "success": True,
            "type": "directory",
            "path": path,
            "name": target_path.name if path else "root",
            "parent": parent_path,
            "items": items,
            "folders_count": len(folders),
            "files_count": len(files)
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í´ë” íƒìƒ‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í´ë” íƒìƒ‰ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/browse/upload")
async def browse_upload(
    file: UploadFile = File(...),
    path: str = Form(default="")
):
    """
    ë²”ìš© íŒŒì¼ ì—…ë¡œë“œ - ì§€ì •ëœ ê²½ë¡œì— íŒŒì¼ ì—…ë¡œë“œ

    - path: ì—…ë¡œë“œí•  í´ë” ê²½ë¡œ (BASE_DIR ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ)
    - ë³´ì•ˆ: BASE_DIR í•˜ìœ„ë§Œ ì ‘ê·¼ ê°€ëŠ¥
    """
    try:
        # ê²½ë¡œ ì •ê·œí™”
        path = path.replace("\\", "/").strip("/")

        # ë³´ì•ˆ ê²€ì‚¬
        if ".." in path:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        # ì „ì²´ ê²½ë¡œ ê³„ì‚°
        if path:
            target_dir = BASE_DIR / path
        else:
            target_dir = BASE_DIR

        # ê²½ë¡œê°€ BASE_DIR í•˜ìœ„ì¸ì§€ í™•ì¸
        try:
            target_dir.resolve().relative_to(BASE_DIR.resolve())
        except ValueError:
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")

        # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ ìƒì„±
        target_dir.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ëª… ê²€ì¦
        filename = file.filename
        if ".." in filename or "/" in filename or "\\" in filename:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤")

        # íŒŒì¼ ì €ì¥ ê²½ë¡œ
        file_path = target_dir / filename

        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        content = await file.read()

        # ì´ë¯¸ì§€ íŒŒì¼ ì—¬ë¶€ í™•ì¸
        file_ext = '.' + filename.split('.')[-1].lower() if '.' in filename else ''
        is_binary = file_ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp', '.ico', '.pdf', '.zip']

        if is_binary:
            with open(file_path, 'wb') as f:
                f.write(content)
        else:
            try:
                content_str = content.decode('utf-8')
            except UnicodeDecodeError:
                content_str = content.decode('cp949', errors='replace')
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content_str)

        full_path = f"{path}/{filename}" if path else filename
        logger.info(f"ë²”ìš© ì—…ë¡œë“œ ì™„ë£Œ: {full_path} ({len(content)} bytes)")

        return JSONResponse({
            "success": True,
            "message": f"íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
            "filename": filename,
            "path": path,
            "full_path": full_path,
            "size": len(content)
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë²”ìš© ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/browse/create-folder")
async def create_folder(path: str = Form(...)):
    """
    ìƒˆ í´ë” ìƒì„±

    - path: ìƒì„±í•  í´ë”ì˜ ì „ì²´ ê²½ë¡œ (BASE_DIR ê¸°ì¤€)
    """
    try:
        path = path.replace("\\", "/").strip("/")

        if ".." in path:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ê²½ë¡œì…ë‹ˆë‹¤")

        target_path = BASE_DIR / path

        try:
            target_path.resolve().relative_to(BASE_DIR.resolve())
        except ValueError:
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤")

        if target_path.exists():
            raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í´ë”ì…ë‹ˆë‹¤")

        target_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"í´ë” ìƒì„±: {path}")

        return JSONResponse({
            "success": True,
            "message": "í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "path": path
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í´ë” ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"í´ë” ìƒì„± ì‹¤íŒ¨: {str(e)}")


# ============================================
# ì™„ì „ ìë™í™” ë³€í™˜ API
# ============================================

# ìë™í™” ë³€í™˜ê¸° ì´ˆê¸°í™”
try:
    from auto_election_converter import AutoElectionConverter
    auto_converter = AutoElectionConverter()
    logger.info("ì™„ì „ ìë™í™” ë³€í™˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    auto_converter = None
    logger.warning(f"ì™„ì „ ìë™í™” ë³€í™˜ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


@app.post("/api/auto-convert")
async def auto_convert_election(
    file: UploadFile = File(...),
    title: Optional[str] = Form(default=None),
    save_folder: Optional[str] = Form(default=None),
    create_images_folder: Optional[str] = Form(default=None)
):
    """
    ì™„ì „ ìë™í™” ì„ ê±°ê³µë³´ë¬¼ ë³€í™˜ API

    - PDF ì—…ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ:
      1. ì •ë‹¹ ê°ì§€ ë° í…Œë§ˆ ì ìš©
      2. í›„ë³´ì ì •ë³´ ì¶”ì¶œ
      3. ê³µì•½/ê²½ë ¥ êµ¬ì¡°í™”
      4. ëª¨ë°”ì¼ ìµœì í™” HTML ìƒì„±

    Parameters:
    - file: PDF íŒŒì¼
    - title: ì¶œë ¥ íŒŒì¼ ì œëª© (ì„ íƒì‚¬í•­)
    - save_folder: ì €ì¥í•  í•˜ìœ„ í´ë”ëª… (ì„ íƒì‚¬í•­, ì˜ˆ: ë¯¼ì£¼-ì´ê´‘ì¬)
    - create_images_folder: images í•˜ìœ„ í´ë” ìƒì„± ì—¬ë¶€ (ì„ íƒì‚¬í•­, "true"ì¸ ê²½ìš° ìƒì„±)

    Returns:
    - success: ì„±ê³µ ì—¬ë¶€
    - result: ë³€í™˜ ê²°ê³¼ (URL, íŒŒì¼ëª…, ì¶”ì¶œëœ ì •ë³´)
    """
    if auto_converter is None:
        raise HTTPException(
            status_code=500,
            detail="ìë™í™” ë³€í™˜ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        )

    # íŒŒì¼ ê²€ì¦
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")

    # íŒŒì¼ í¬ê¸° ì œí•œ (50MB)
    MAX_FILE_SIZE = 50 * 1024 * 1024
    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ëŠ” 50MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ê³ ìœ  ID ìƒì„±
    job_id = str(uuid.uuid4())[:8]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # íŒŒì¼ ì €ì¥
    original_filename = file.filename
    safe_filename = f"{job_id}_{timestamp}.pdf"
    upload_path = UPLOAD_DIR / safe_filename

    try:
        with open(upload_path, "wb") as f:
            f.write(content)

        logger.info(f"[{job_id}] ì™„ì „ ìë™í™” ë³€í™˜ ì‹œì‘: {original_filename}")

        # ìë™ ë³€í™˜ ì‹¤í–‰ (ì›ë³¸ íŒŒì¼ëª… ì „ë‹¬)
        brochure = auto_converter.convert(str(upload_path), original_filename=original_filename)

        # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
        if title:
            safe_title = "".join(c for c in title if c.isalnum() or c in ('_', '-', ' ') or ord(c) > 127).strip()
            output_filename = f"{safe_title}_{timestamp}.html"
        elif brochure.candidate.name:
            output_filename = f"{brochure.candidate.name}_{timestamp}.html"
        else:
            output_filename = f"AUTO_{job_id}_{timestamp}.html"

        # ì €ì¥ ê²½ë¡œ ì„¤ì • (í•˜ìœ„ í´ë” ì§€ì›)
        if save_folder:
            # ë³´ì•ˆ: ìƒìœ„ ë””ë ‰í† ë¦¬ ì ‘ê·¼ ë°©ì§€
            if ".." in save_folder:
                raise HTTPException(status_code=400, detail="ì˜ëª»ëœ í´ë”ëª…ì…ë‹ˆë‹¤")
            # í•˜ìœ„ í´ë” ìƒì„±
            output_dir = OUTPUT_DIR / save_folder
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / output_filename
            output_url_path = f"/outputs/{save_folder}/{output_filename}"

            # images í´ë” ìƒì„± (create_images_folderê°€ "true"ì¸ ê²½ìš°)
            if create_images_folder == "true":
                images_dir = output_dir / "images"
                images_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"[{job_id}] images í´ë” ìƒì„±ë¨: {images_dir}")
        else:
            output_dir = OUTPUT_DIR
            output_path = OUTPUT_DIR / output_filename
            output_url_path = f"/outputs/{output_filename}"

        # HTML ìƒì„± (ì´ë¯¸ì§€ í´ë” ê²½ë¡œ ì „ë‹¬)
        html_content = auto_converter.generate_html(brochure, output_folder=str(output_dir))

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        logger.info(f"[{job_id}] ì™„ì „ ìë™í™” ë³€í™˜ ì™„ë£Œ: {output_filename}")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files(job_id=job_id, keep_outputs=True)

        # í•™ìŠµ ì‹œìŠ¤í…œì— ê¸°ë¡ (ê¸°ì¡´ + ëŠ¥ë™í˜• í•™ìŠµ)
        try:
            # ê¸°ì¡´ í•™ìŠµ ì‹œìŠ¤í…œ
            learning_system.log_conversion(job_id, {
                "filename": original_filename,
                "content_type": "election",
                "page_count": len(brochure.raw_pages),
                "is_image_based": any(p.get("ocr_used") for p in brochure.raw_pages),
                "ocr_used": any(p.get("ocr_used") for p in brochure.raw_pages),
                "auto_converted": True,
                "party_detected": brochure.candidate.party,
                "candidate_name": brochure.candidate.name
            })

            # ëŠ¥ë™í˜• í•™ìŠµ ì—”ì§„ì—ë„ ê¸°ë¡
            if active_learning_engine is not None:
                active_learning_engine.record_conversion({
                    "candidate_name": brochure.candidate.name,
                    "party": brochure.candidate.party,
                    "candidate_type": brochure.candidate_type,
                    "region": f"{brochure.region_metro}/{brochure.region_district}",
                    "pledge_count": len(brochure.core_pledges),
                    "career_count": len(brochure.careers),
                    "page_count": len(brochure.raw_pages),
                    "filename": original_filename,
                    "job_id": job_id,
                    "output_path": str(output_path),
                    "theme_color": brochure.theme.primary_color if brochure.theme else "#6366F1"
                })
                logger.info(f"[{job_id}] ëŠ¥ë™í˜• í•™ìŠµ ì—”ì§„ì— ë³€í™˜ ê¸°ë¡ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"í•™ìŠµ ë°ì´í„° ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")

        return JSONResponse({
            "success": True,
            "job_id": job_id,
            "message": "ì™„ì „ ìë™í™” ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "result": {
                "url": output_url_path,
                "filename": output_filename,
                "save_folder": save_folder or "",
                "original_filename": original_filename,
                "candidate": {
                    "name": brochure.candidate.name,
                    "party": brochure.candidate.party,
                    "symbol": brochure.candidate.symbol,
                    "position": brochure.candidate.position,
                    "district": brochure.candidate.district
                },
                "statistics": {
                    "page_count": len(brochure.raw_pages),
                    "pledge_count": len(brochure.core_pledges),
                    "career_count": len(brochure.careers),
                    "ocr_pages": sum(1 for p in brochure.raw_pages if p.get("ocr_used"))
                },
                "theme": {
                    "party_color": brochure.theme.primary_color if brochure.theme else "#6366F1"
                },
                "created_at": datetime.now().isoformat()
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[{job_id}] ì™„ì „ ìë™í™” ë³€í™˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        cleanup_temp_files(job_id=job_id, keep_outputs=False)
        raise HTTPException(status_code=500, detail=f"ë³€í™˜ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/auto-convert/status")
async def get_auto_convert_status():
    """
    ì™„ì „ ìë™í™” ë³€í™˜ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    """
    return JSONResponse({
        "success": True,
        "auto_converter_ready": auto_converter is not None,
        "vision_ocr_ready": auto_converter.vision_ocr is not None if auto_converter else False,
        "supported_parties": [
            {"id": "ppp", "name": "êµ­ë¯¼ì˜í˜", "color": "#E11D48"},
            {"id": "dpk", "name": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹", "color": "#004EA2"},
            {"id": "jp", "name": "ì •ì˜ë‹¹", "color": "#FFCC00"},
            {"id": "pp", "name": "êµ­ë¯¼ì˜ë‹¹", "color": "#EA5504"},
            {"id": "rp", "name": "ê°œí˜ì‹ ë‹¹", "color": "#FF6B35"},
            {"id": "nrp", "name": "ìƒˆë¡œìš´ë¯¸ë˜", "color": "#10B981"},
            {"id": "independent", "name": "ë¬´ì†Œì†", "color": "#6B7280"}
        ],
        "features": [
            "ì •ë‹¹ ìë™ ê°ì§€",
            "í…Œë§ˆ ìƒ‰ìƒ ìë™ ì ìš©",
            "í›„ë³´ì ì •ë³´ ìë™ ì¶”ì¶œ",
            "ê³µì•½/ê²½ë ¥ êµ¬ì¡°í™”",
            "ëª¨ë°”ì¼ ìµœì í™” HTML",
            "SNS ë§í¬ ìë™ ì—°ê²°",
            "ì „í™”ë²ˆí˜¸ í´ë¦­ í†µí™”"
        ]
    })


@app.post("/api/batch-convert")
async def batch_convert_elections(
    files: List[UploadFile] = File(...)
):
    """
    ë‹¤ì¤‘ íŒŒì¼ ì¼ê´„ ìë™ ë³€í™˜ API

    ì—¬ëŸ¬ PDFë¥¼ í•œë²ˆì— ì—…ë¡œë“œí•˜ì—¬ ì¼ê´„ ë³€í™˜í•©ë‹ˆë‹¤.

    Parameters:
    - files: PDF íŒŒì¼ ëª©ë¡ (ìµœëŒ€ 20ê°œ)

    Returns:
    - success: ì„±ê³µ ì—¬ë¶€
    - results: ê° íŒŒì¼ë³„ ë³€í™˜ ê²°ê³¼
    """
    if auto_converter is None:
        raise HTTPException(
            status_code=500,
            detail="ìë™í™” ë³€í™˜ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        )

    if len(files) > 20:
        raise HTTPException(status_code=400, detail="í•œë²ˆì— ìµœëŒ€ 20ê°œ íŒŒì¼ë§Œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤")

    results = []
    success_count = 0
    fail_count = 0

    for file in files:
        job_id = str(uuid.uuid4())[:8]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        try:
            if not file.filename.lower().endswith('.pdf'):
                results.append({
                    "filename": file.filename,
                    "success": False,
                    "error": "PDF íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤"
                })
                fail_count += 1
                continue

            content = await file.read()

            # íŒŒì¼ ì €ì¥
            safe_filename = f"{job_id}_{timestamp}.pdf"
            upload_path = UPLOAD_DIR / safe_filename

            with open(upload_path, "wb") as f:
                f.write(content)

            # ìë™ ë³€í™˜
            brochure = auto_converter.convert(str(upload_path))
            html_content = auto_converter.generate_html(brochure)

            # ì¶œë ¥ ì €ì¥
            if brochure.candidate.name:
                output_filename = f"{brochure.candidate.name}_{timestamp}.html"
            else:
                output_filename = f"AUTO_{job_id}_{timestamp}.html"

            output_path = OUTPUT_DIR / output_filename

            with open(output_path, "w", encoding="utf-8") as f:
                f.write(html_content)

            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            cleanup_temp_files(job_id=job_id, keep_outputs=True)

            results.append({
                "filename": file.filename,
                "success": True,
                "output_url": f"/outputs/{output_filename}",
                "candidate_name": brochure.candidate.name,
                "party": brochure.candidate.party
            })
            success_count += 1

        except Exception as e:
            logger.error(f"ì¼ê´„ ë³€í™˜ ì˜¤ë¥˜ ({file.filename}): {str(e)}")
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
            fail_count += 1

    return JSONResponse({
        "success": True,
        "message": f"ì¼ê´„ ë³€í™˜ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {fail_count}ê°œ",
        "statistics": {
            "total": len(files),
            "success": success_count,
            "failed": fail_count
        },
        "results": results
    })


# ì„œë²„ ì‹¤í–‰ (ê°œë°œìš©)
if __name__ == "__main__":
    import uvicorn

    print("=" * 50)
    print("StudySnap Backend Server")
    print("=" * 50)
    print(f"Upload Directory: {UPLOAD_DIR}")
    print(f"Output Directory: {OUTPUT_DIR}")
    print("=" * 50)

    # ì„œë²„ ì‹œì‘ ì‹œ 24ì‹œê°„ ì´ìƒ ëœ ì„ì‹œ íŒŒì¼ ìë™ ì •ë¦¬
    print("\n[INFO] Cleaning up temp files...")
    try:
        deleted_files = cleanup_temp_files(
            job_id=None,
            keep_outputs=True,
            cleanup_old_files=True,
            max_age_hours=24
        )
        if deleted_files:
            print(f"[OK] Deleted {len(deleted_files)} old temp files")
        else:
            print("[OK] No temp files to clean")
    except Exception as e:
        print(f"[WARNING] Cleanup failed: {str(e)}")

    print("=" * 50)
    print("[INFO] Starting server...")
    print("=" * 50)

    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
